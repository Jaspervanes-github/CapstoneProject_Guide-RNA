{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robin\\anaconda3\\envs\\dnabert\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56888 entries, 0 to 56887\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   seq     56888 non-null  object \n",
      " 1   y       56888 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 889.0+ KB\n",
      "None\n",
      "                     seq         y\n",
      "0  AAAAAAAAACTCCAAAACCCT  0.093147\n",
      "1  AAAAAACAACAAGAAGCACAA  0.064951\n",
      "2  AAAAAACACAAGCAAGACCGT  0.061797\n",
      "3  AAAAAACAGATGCCACCTGTG  0.057246\n",
      "4  AAAAAACCCGTAGATAGCCTC  0.067596\n"
     ]
    }
   ],
   "source": [
    "modelpath = \"zhihan1996/DNABERT-2-117M\"\n",
    "df = pd.read_csv(\"./sample_data/esp_decoded.csv\")\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlMElEQVR4nO3dfXRU9YH/8U8eyCRSZsLDZiazRojaCqlUKqlxROhac4glusuWbmVJkW0j1Jp0C1ExFA34GBqfUUoWtQ3nFBZ0j7CU0Eg2LGSFGDCSFQNEXaDgshP0QGYAJQ/k/v7w5P4YiUpwkmG+vF/nzDnNvd+5873fqvM+NzM3MZZlWQIAADBMbKQnAAAA0BeIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGio/0BCKpq6tLhw8f1qBBgxQTExPp6QAAgHNgWZaOHz8ur9er2Ngvvl5zUUfO4cOHlZaWFulpAACA83Do0CFdeumlX7j/oo6cQYMGSfpskZxOZ4RnAwAAzkUwGFRaWpr9Pv5FLurI6f4VldPpJHIAAIgyX/VREz54DAAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAI8VHegIA0FdGFFdGegq9dmBRbqSnABiDKzkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIvY6c2tpa3XbbbfJ6vYqJidHatWtD9luWpZKSEqWmpiopKUnZ2dl6//33Q8YcPXpUeXl5cjqdSk5OVn5+vk6cOBEy5p133tH48eOVmJiotLQ0lZWVnTWXV199VSNHjlRiYqJGjx6tDRs29PZ0AACAoXodOSdPntQ111yjJUuW9Li/rKxMixcvVnl5uerr6zVw4EDl5OTo1KlT9pi8vDw1NTWpurpa69evV21trWbNmmXvDwaDmjhxooYPH66GhgY98cQTWrhwoZYtW2aP2bZtm/7xH/9R+fn52rlzpyZPnqzJkyfr3Xff7e0pAQAAA8VYlmWd95NjYrRmzRpNnjxZ0mdXcbxer+655x7de++9kqRAICC3262KigpNnTpVe/bsUUZGhnbs2KHMzExJUlVVlSZNmqQPP/xQXq9XS5cu1fz58+X3+5WQkCBJKi4u1tq1a7V3715J0u23366TJ09q/fr19nyuv/56jRkzRuXl5ec0/2AwKJfLpUAgIKfTeb7LAOACNaK4MtJT6LUDi3IjPQXggneu799h/UzO/v375ff7lZ2dbW9zuVzKyspSXV2dJKmurk7Jycl24EhSdna2YmNjVV9fb4+ZMGGCHTiSlJOTo+bmZh07dswec+brdI/pfp2etLW1KRgMhjwAAICZwho5fr9fkuR2u0O2u91ue5/f71dKSkrI/vj4eA0ZMiRkTE/HOPM1vmhM9/6elJaWyuVy2Y+0tLTeniIAAIgSF9W3q+bNm6dAIGA/Dh06FOkpAQCAPhLWyPF4PJKklpaWkO0tLS32Po/HoyNHjoTs7+zs1NGjR0PG9HSMM1/ji8Z07++Jw+GQ0+kMeQAAADOFNXLS09Pl8XhUU1NjbwsGg6qvr5fP55Mk+Xw+tba2qqGhwR6zadMmdXV1KSsryx5TW1urjo4Oe0x1dbWuuuoqDR482B5z5ut0j+l+HQAAcHHrdeScOHFCjY2NamxslPTZh40bGxt18OBBxcTEaPbs2Xr00Ue1bt067dq1S3fccYe8Xq/9DaxRo0bplltu0cyZM7V9+3Zt3bpVhYWFmjp1qrxeryRp2rRpSkhIUH5+vpqamrR69Wo999xzKioqsufx61//WlVVVXrqqae0d+9eLVy4UG+99ZYKCwu//qoAAICoF9/bJ7z11lu66aab7J+7w2PGjBmqqKjQ3LlzdfLkSc2aNUutra268cYbVVVVpcTERPs5K1asUGFhoW6++WbFxsZqypQpWrx4sb3f5XJp48aNKigo0NixYzVs2DCVlJSE3Evnhhtu0MqVK/XAAw/oN7/5jb75zW9q7dq1uvrqq89rIQAAgFm+1n1yoh33yQHMxn1yADNF5D45AAAAFwoiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEbq9R/oBAD0Hf7eFhA+RA6AcxKNb74ALm78ugoAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkcIeOadPn9aDDz6o9PR0JSUl6YorrtAjjzwiy7LsMZZlqaSkRKmpqUpKSlJ2drbef//9kOMcPXpUeXl5cjqdSk5OVn5+vk6cOBEy5p133tH48eOVmJiotLQ0lZWVhft0AABAlAp75Pz2t7/V0qVL9cILL2jPnj367W9/q7KyMj3//PP2mLKyMi1evFjl5eWqr6/XwIEDlZOTo1OnTtlj8vLy1NTUpOrqaq1fv161tbWaNWuWvT8YDGrixIkaPny4Ghoa9MQTT2jhwoVatmxZuE8JAABEoRjrzEssYXDrrbfK7Xbr5ZdftrdNmTJFSUlJ+uMf/yjLsuT1enXPPffo3nvvlSQFAgG53W5VVFRo6tSp2rNnjzIyMrRjxw5lZmZKkqqqqjRp0iR9+OGH8nq9Wrp0qebPny+/36+EhARJUnFxsdauXau9e/ee01yDwaBcLpcCgYCcTmc4lwEwzojiykhPAReoA4tyIz0FXGTO9f077FdybrjhBtXU1Oi9996TJP33f/+33njjDf3whz+UJO3fv19+v1/Z2dn2c1wul7KyslRXVydJqqurU3Jysh04kpSdna3Y2FjV19fbYyZMmGAHjiTl5OSoublZx44d63FubW1tCgaDIQ8AAGCm+HAfsLi4WMFgUCNHjlRcXJxOnz6txx57THl5eZIkv98vSXK73SHPc7vd9j6/36+UlJTQicbHa8iQISFj0tPTzzpG977BgwefNbfS0lI99NBDYThLAABwoQv7lZxXXnlFK1as0MqVK/X2229r+fLlevLJJ7V8+fJwv1SvzZs3T4FAwH4cOnQo0lMCAAB9JOxXcu677z4VFxdr6tSpkqTRo0frL3/5i0pLSzVjxgx5PB5JUktLi1JTU+3ntbS0aMyYMZIkj8ejI0eOhBy3s7NTR48etZ/v8XjU0tISMqb75+4xn+dwOORwOL7+SQIAgAte2K/kfPLJJ4qNDT1sXFycurq6JEnp6enyeDyqqamx9weDQdXX18vn80mSfD6fWltb1dDQYI/ZtGmTurq6lJWVZY+pra1VR0eHPaa6ulpXXXVVj7+qAgAAF5ewR85tt92mxx57TJWVlTpw4IDWrFmjp59+Wn//938vSYqJidHs2bP16KOPat26ddq1a5fuuOMOeb1eTZ48WZI0atQo3XLLLZo5c6a2b9+urVu3qrCwUFOnTpXX65UkTZs2TQkJCcrPz1dTU5NWr16t5557TkVFReE+JQAAEIXC/uuq559/Xg8++KDuvvtuHTlyRF6vV7/4xS9UUlJij5k7d65OnjypWbNmqbW1VTfeeKOqqqqUmJhoj1mxYoUKCwt18803KzY2VlOmTNHixYvt/S6XSxs3blRBQYHGjh2rYcOGqaSkJOReOgAA4OIV9vvkRBPukwOcO+6Tgy/CfXLQ3yJ2nxwAAIALAZEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMFB/pCQAXmxHFlZGeAgBcFLiSAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwUp9Ezv/+7//qpz/9qYYOHaqkpCSNHj1ab731lr3fsiyVlJQoNTVVSUlJys7O1vvvvx9yjKNHjyovL09Op1PJycnKz8/XiRMnQsa88847Gj9+vBITE5WWlqaysrK+OB0AABCFwh45x44d07hx4zRgwAD9+c9/1u7du/XUU09p8ODB9piysjItXrxY5eXlqq+v18CBA5WTk6NTp07ZY/Ly8tTU1KTq6mqtX79etbW1mjVrlr0/GAxq4sSJGj58uBoaGvTEE09o4cKFWrZsWbhPCQAARKEYy7KscB6wuLhYW7du1X/913/1uN+yLHm9Xt1zzz269957JUmBQEBut1sVFRWaOnWq9uzZo4yMDO3YsUOZmZmSpKqqKk2aNEkffvihvF6vli5dqvnz58vv9yshIcF+7bVr12rv3r3nNNdgMCiXy6VAICCn0xmGswe+2ojiykhPAQirA4tyIz0FXGTO9f077Fdy1q1bp8zMTP3DP/yDUlJS9N3vflcvvviivX///v3y+/3Kzs62t7lcLmVlZamurk6SVFdXp+TkZDtwJCk7O1uxsbGqr6+3x0yYMMEOHEnKyclRc3Ozjh07Fu7TAgAAUSbskbNv3z4tXbpU3/zmN/X666/rl7/8pf75n/9Zy5cvlyT5/X5JktvtDnme2+229/n9fqWkpITsj4+P15AhQ0LG9HSMM1/j89ra2hQMBkMeAADATPHhPmBXV5cyMzP1+OOPS5K++93v6t1331V5eblmzJgR7pfrldLSUj300EMRnQMAAOgfYb+Sk5qaqoyMjJBto0aN0sGDByVJHo9HktTS0hIypqWlxd7n8Xh05MiRkP2dnZ06evRoyJiejnHma3zevHnzFAgE7MehQ4fO5xQBAEAUCHvkjBs3Ts3NzSHb3nvvPQ0fPlySlJ6eLo/Ho5qaGnt/MBhUfX29fD6fJMnn86m1tVUNDQ32mE2bNqmrq0tZWVn2mNraWnV0dNhjqqurddVVV4V8k+tMDodDTqcz5AEAAMwU9siZM2eO3nzzTT3++OP64IMPtHLlSi1btkwFBQWSpJiYGM2ePVuPPvqo1q1bp127dumOO+6Q1+vV5MmTJX125eeWW27RzJkztX37dm3dulWFhYWaOnWqvF6vJGnatGlKSEhQfn6+mpqatHr1aj333HMqKioK9ykBAIAoFPbP5Hzve9/TmjVrNG/ePD388MNKT0/Xs88+q7y8PHvM3LlzdfLkSc2aNUutra268cYbVVVVpcTERHvMihUrVFhYqJtvvlmxsbGaMmWKFi9ebO93uVzauHGjCgoKNHbsWA0bNkwlJSUh99IBAAAXr7DfJyeacJ8cRAL3yYFpuE8O+tu5vn+H/UoOAODiEo3hTphdHPgDnQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwUnykJwB8HSOKKyM9BQDABYorOQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADBSfKQngAvHiOLKSE8BAICw4UoOAAAwUp9HzqJFixQTE6PZs2fb206dOqWCggINHTpU3/jGNzRlyhS1tLSEPO/gwYPKzc3VJZdcopSUFN13333q7OwMGbN582Zde+21cjgcuvLKK1VRUdHXpwMAAKJEn0bOjh079C//8i/6zne+E7J9zpw5+tOf/qRXX31VW7Zs0eHDh/WjH/3I3n/69Gnl5uaqvb1d27Zt0/Lly1VRUaGSkhJ7zP79+5Wbm6ubbrpJjY2Nmj17tu688069/vrrfXlKAAAgSvRZ5Jw4cUJ5eXl68cUXNXjwYHt7IBDQyy+/rKefflo/+MEPNHbsWP3hD3/Qtm3b9Oabb0qSNm7cqN27d+uPf/yjxowZox/+8Id65JFHtGTJErW3t0uSysvLlZ6erqeeekqjRo1SYWGhfvzjH+uZZ57pq1MCAABRpM8ip6CgQLm5ucrOzg7Z3tDQoI6OjpDtI0eO1GWXXaa6ujpJUl1dnUaPHi23222PycnJUTAYVFNTkz3m88fOycmxjwEAAC5uffLtqlWrVuntt9/Wjh07ztrn9/uVkJCg5OTkkO1ut1t+v98ec2bgdO/v3vdlY4LBoD799FMlJSWd9dptbW1qa2uzfw4Gg70/OQAAEBXCfiXn0KFD+vWvf60VK1YoMTEx3If/WkpLS+VyuexHWlpapKcEAAD6SNgjp6GhQUeOHNG1116r+Ph4xcfHa8uWLVq8eLHi4+PldrvV3t6u1tbWkOe1tLTI4/FIkjwez1nftur++avGOJ3OHq/iSNK8efMUCATsx6FDh8JxygAA4AIU9si5+eabtWvXLjU2NtqPzMxM5eXl2f97wIABqqmpsZ/T3NysgwcPyufzSZJ8Pp927dqlI0eO2GOqq6vldDqVkZFhjznzGN1juo/RE4fDIafTGfIAAABmCvtncgYNGqSrr746ZNvAgQM1dOhQe3t+fr6Kioo0ZMgQOZ1O/epXv5LP59P1118vSZo4caIyMjI0ffp0lZWVye/364EHHlBBQYEcDock6a677tILL7yguXPn6uc//7k2bdqkV155RZWV3LUXAABE6M86PPPMM4qNjdWUKVPU1tamnJwc/e53v7P3x8XFaf369frlL38pn8+ngQMHasaMGXr44YftMenp6aqsrNScOXP03HPP6dJLL9VLL72knJycSJwSAAC4wMRYlmVFehKREgwG5XK5FAgE+NWV+NtVAC4eBxblRnoK+BrO9f2bv10FAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADBSfKQnYKoRxZWRngIAABc1ruQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIxE5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADBS2COntLRU3/ve9zRo0CClpKRo8uTJam5uDhlz6tQpFRQUaOjQofrGN76hKVOmqKWlJWTMwYMHlZubq0suuUQpKSm677771NnZGTJm8+bNuvbaa+VwOHTllVeqoqIi3KcDAACiVNgjZ8uWLSooKNCbb76p6upqdXR0aOLEiTp58qQ9Zs6cOfrTn/6kV199VVu2bNHhw4f1ox/9yN5/+vRp5ebmqr29Xdu2bdPy5ctVUVGhkpISe8z+/fuVm5urm266SY2NjZo9e7buvPNOvf766+E+JQAAEIViLMuy+vIFPvroI6WkpGjLli2aMGGCAoGA/uqv/korV67Uj3/8Y0nS3r17NWrUKNXV1en666/Xn//8Z9166606fPiw3G63JKm8vFz333+/PvroIyUkJOj+++9XZWWl3n33Xfu1pk6dqtbWVlVVVZ3T3ILBoFwulwKBgJxOZ1jPe0RxZViPBwAInwOLciM9BXwN5/r+3eefyQkEApKkIUOGSJIaGhrU0dGh7Oxse8zIkSN12WWXqa6uTpJUV1en0aNH24EjSTk5OQoGg2pqarLHnHmM7jHdx+hJW1ubgsFgyAMAAJgpvi8P3tXVpdmzZ2vcuHG6+uqrJUl+v18JCQlKTk4OGet2u+X3++0xZwZO9/7ufV82JhgM6tNPP1VSUtJZ8yktLdVDDz0UlnMDAESvaLzaztWn3uvTKzkFBQV69913tWrVqr58mXM2b948BQIB+3Ho0KFITwkAAPSRPruSU1hYqPXr16u2tlaXXnqpvd3j8ai9vV2tra0hV3NaWlrk8XjsMdu3bw85Xve3r84c8/lvZLW0tMjpdPZ4FUeSHA6HHA7H1z43AABw4Qv7lRzLslRYWKg1a9Zo06ZNSk9PD9k/duxYDRgwQDU1Nfa25uZmHTx4UD6fT5Lk8/m0a9cuHTlyxB5TXV0tp9OpjIwMe8yZx+ge030MAABwcQv7lZyCggKtXLlS//7v/65BgwbZn6FxuVxKSkqSy+VSfn6+ioqKNGTIEDmdTv3qV7+Sz+fT9ddfL0maOHGiMjIyNH36dJWVlcnv9+uBBx5QQUGBfSXmrrvu0gsvvKC5c+fq5z//uTZt2qRXXnlFlZXR93tWAAAQfmG/krN06VIFAgH9zd/8jVJTU+3H6tWr7THPPPOMbr31Vk2ZMkUTJkyQx+PRa6+9Zu+Pi4vT+vXrFRcXJ5/Pp5/+9Ke644479PDDD9tj0tPTVVlZqerqal1zzTV66qmn9NJLLyknJyfcpwQAAKJQn98n50LGfXIAANGCb1f9fxfMfXIAAAAigcgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABiJyAEAAEYicgAAgJGIHAAAYCQiBwAAGInIAQAARiJyAACAkYgcAABgJCIHAAAYicgBAABGInIAAICRiBwAAGAkIgcAABgpPtITAAAAX21EcWWkp9BrBxblRvT1uZIDAACMROQAAAAjRX3kLFmyRCNGjFBiYqKysrK0ffv2SE8JAABcAKI6clavXq2ioiItWLBAb7/9tq655hrl5OToyJEjkZ4aAACIsKiOnKefflozZ87Uz372M2VkZKi8vFyXXHKJfv/730d6agAAIMKi9ttV7e3tamho0Lx58+xtsbGxys7OVl1dXY/PaWtrU1tbm/1zIBCQJAWDwbDPr6vtk7AfEwCAaNIX769nHteyrC8dF7WR8/HHH+v06dNyu90h291ut/bu3dvjc0pLS/XQQw+dtT0tLa1P5ggAwMXM9WzfHv/48eNyuVxfuD9qI+d8zJs3T0VFRfbPXV1dOnr0qIYOHaqYmJjzPm4wGFRaWpoOHTokp9MZjqniC7DW/Ye17j+sdf9hrftPX661ZVk6fvy4vF7vl46L2sgZNmyY4uLi1NLSErK9paVFHo+nx+c4HA45HI6QbcnJyWGbk9Pp5F+afsJa9x/Wuv+w1v2Hte4/fbXWX3YFp1vUfvA4ISFBY8eOVU1Njb2tq6tLNTU18vl8EZwZAAC4EETtlRxJKioq0owZM5SZmanrrrtOzz77rE6ePKmf/exnkZ4aAACIsKiOnNtvv10fffSRSkpK5Pf7NWbMGFVVVZ31YeS+5nA4tGDBgrN+FYbwY637D2vdf1jr/sNa958LYa1jrK/6/hUAAEAUitrP5AAAAHwZIgcAABiJyAEAAEYicgAAgJGInHO0ZMkSjRgxQomJicrKytL27du/dPyrr76qkSNHKjExUaNHj9aGDRv6aabRrzdr/eKLL2r8+PEaPHiwBg8erOzs7K/8/wb/X2//ue62atUqxcTEaPLkyX07QYP0dq1bW1tVUFCg1NRUORwOfetb3+K/I+eot2v97LPP6qqrrlJSUpLS0tI0Z84cnTp1qp9mG71qa2t12223yev1KiYmRmvXrv3K52zevFnXXnutHA6HrrzySlVUVPTtJC18pVWrVlkJCQnW73//e6upqcmaOXOmlZycbLW0tPQ4fuvWrVZcXJxVVlZm7d6923rggQesAQMGWLt27ernmUef3q71tGnTrCVLllg7d+609uzZY/3TP/2T5XK5rA8//LCfZx59ervW3fbv32/99V//tTV+/Hjr7/7u7/pnslGut2vd1tZmZWZmWpMmTbLeeOMNa//+/dbmzZutxsbGfp559OntWq9YscJyOBzWihUrrP3791uvv/66lZqaas2ZM6efZx59NmzYYM2fP9967bXXLEnWmjVrvnT8vn37rEsuucQqKiqydu/ebT3//PNWXFycVVVV1WdzJHLOwXXXXWcVFBTYP58+fdryer1WaWlpj+N/8pOfWLm5uSHbsrKyrF/84hd9Ok8T9HatP6+zs9MaNGiQtXz58r6aojHOZ607OzutG264wXrppZesGTNmEDnnqLdrvXTpUuvyyy+32tvb+2uKxujtWhcUFFg/+MEPQrYVFRVZ48aN69N5muZcImfu3LnWt7/97ZBtt99+u5WTk9Nn8+LXVV+hvb1dDQ0Nys7OtrfFxsYqOztbdXV1PT6nrq4uZLwk5eTkfOF4fOZ81vrzPvnkE3V0dGjIkCF9NU0jnO9aP/zww0pJSVF+fn5/TNMI57PW69atk8/nU0FBgdxut66++mo9/vjjOn36dH9NOyqdz1rfcMMNamhosH+ltW/fPm3YsEGTJk3qlzlfTCLx3hjVdzzuDx9//LFOnz591l2U3W639u7d2+Nz/H5/j+P9fn+fzdME57PWn3f//ffL6/We9S8SQp3PWr/xxht6+eWX1djY2A8zNMf5rPW+ffu0adMm5eXlacOGDfrggw909913q6OjQwsWLOiPaUel81nradOm6eOPP9aNN94oy7LU2dmpu+66S7/5zW/6Y8oXlS96bwwGg/r000+VlJQU9tfkSg6MsWjRIq1atUpr1qxRYmJipKdjlOPHj2v69Ol68cUXNWzYsEhPx3hdXV1KSUnRsmXLNHbsWN1+++2aP3++ysvLIz0142zevFmPP/64fve73+ntt9/Wa6+9psrKSj3yyCORnhrCgCs5X2HYsGGKi4tTS0tLyPaWlhZ5PJ4en+PxeHo1Hp85n7Xu9uSTT2rRokX6j//4D33nO9/py2kaobdr/T//8z86cOCAbrvtNntbV1eXJCk+Pl7Nzc264oor+nbSUep8/rlOTU3VgAEDFBcXZ28bNWqU/H6/2tvblZCQ0Kdzjlbns9YPPvigpk+frjvvvFOSNHr0aJ08eVKzZs3S/PnzFRvLtYBw+aL3RqfT2SdXcSSu5HylhIQEjR07VjU1Nfa2rq4u1dTUyOfz9fgcn88XMl6Sqqurv3A8PnM+ay1JZWVleuSRR1RVVaXMzMz+mGrU6+1ajxw5Urt27VJjY6P9+Nu//VvddNNNamxsVFpaWn9OP6qczz/X48aN0wcffGCHpCS99957Sk1NJXC+xPms9SeffHJWyHTHpcWfdgyriLw39tlHmg2yatUqy+FwWBUVFdbu3butWbNmWcnJyZbf77csy7KmT59uFRcX2+O3bt1qxcfHW08++aS1Z88ea8GCBXyF/Bz1dq0XLVpkJSQkWP/2b/9m/d///Z/9OH78eKROIWr0dq0/j29XnbvervXBgwetQYMGWYWFhVZzc7O1fv16KyUlxXr00UcjdQpRo7drvWDBAmvQoEHWv/7rv1r79u2zNm7caF1xxRXWT37yk0idQtQ4fvy4tXPnTmvnzp2WJOvpp5+2du7caf3lL3+xLMuyiouLrenTp9vju79Cft9991l79uyxlixZwlfILxTPP/+8ddlll1kJCQnWddddZ7355pv2vu9///vWjBkzQsa/8sor1re+9S0rISHB+va3v21VVlb284yjV2/Wevjw4Zaksx4LFizo/4lHod7+c30mIqd3ervW27Zts7KysiyHw2Fdfvnl1mOPPWZ1dnb286yjU2/WuqOjw1q4cKF1xRVXWImJiVZaWpp19913W8eOHev/iUeZ//zP/+zxv7/d6ztjxgzr+9///lnPGTNmjJWQkGBdfvnl1h/+8Ic+nWOMZXE9DgAAmIfP5AAAACMROQAAwEhEDgAAMBKRAwAAjETkAAAAIxE5AADASEQOAAAwEpEDAACMROQAAAAjETkAAMBIRA4AADASkQMAAIz0/wAMqLyYO7DnygAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot label distribution\n",
    "plt.hist(df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "#turn df into a dataset\n",
    "raw_dataset = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['seq', 'y'],\n",
      "    num_rows: 56888\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#raw_datasets = raw_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "print(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        modelpath,\n",
    "        \n",
    "        model_max_length=100,\n",
    "        padding_side=\"right\",\n",
    "        use_fast=True,\n",
    "        trust_remote_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 56888/56888 [00:01<00:00, 40738.23 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['seq', 'y', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 56888\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"seq\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "#print(output)\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and validation set\n",
    "tokenized_datasets = tokenized_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['seq', 'y', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 45510\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['seq', 'y', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 11378\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenized_datasets)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"seq\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"y\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.model_max_length)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\", padding=\"longest\", max_length=tokenizer.model_max_length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(\n",
    "#     tokenized_datasets[\"train\"], shuffle=True, batch_size=batch_size, collate_fn=data_collator\n",
    "# )\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], batch_size=batch_size, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin/.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\1d020b803b871a976f5f3d5565f0eac8f2c7bb81\\bert_layers.py:125: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at zhihan1996/DNABERT-2-117M were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(4096, 768, padding_idx=0)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertUnpadAttention(\n",
       "            (self): BertUnpadSelfAttention(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (Wqkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (mlp): BertGatedLinearUnitMLP(\n",
       "            (gated_layers): Linear(in_features=768, out_features=6144, bias=False)\n",
       "            (act): GELU(approximate='none')\n",
       "            (wo): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    modelpath,\n",
    "    cache_dir=None,\n",
    "    num_labels=1,\n",
    "    trust_remote_code=True,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     print(batch['labels'][0])\n",
    "#     break\n",
    "# print({k: v.shape for k, v in batch.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    logits = logits[0]\n",
    "\n",
    "    print(type(labels))\n",
    "    print(type(logits))\n",
    "    print(labels)\n",
    "    print(logits)\n",
    "    print(labels.shape)\n",
    "    print(logits.shape)\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robin\\anaconda3\\envs\\dnabert\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/1068 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  1%|          | 10/1068 [00:26<48:42,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0813, 'learning_rate': 2.9719101123595505e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1068 [00:54<46:57,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0488, 'learning_rate': 2.9438202247191012e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 30/1068 [01:22<50:13,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0447, 'learning_rate': 2.915730337078652e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 40/1068 [01:49<45:45,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0433, 'learning_rate': 2.8876404494382023e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 50/1068 [02:15<45:09,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0381, 'learning_rate': 2.859550561797753e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 60/1068 [02:42<44:49,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.038, 'learning_rate': 2.8314606741573034e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 70/1068 [03:09<44:25,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.037, 'learning_rate': 2.8033707865168537e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 80/1068 [03:36<43:56,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0369, 'learning_rate': 2.7752808988764048e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 90/1068 [04:03<43:25,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0366, 'learning_rate': 2.7471910112359552e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 100/1068 [04:29<42:46,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0353, 'learning_rate': 2.7191011235955055e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 110/1068 [04:57<43:29,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0342, 'learning_rate': 2.6910112359550563e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 120/1068 [05:23<42:11,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0334, 'learning_rate': 2.6629213483146066e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 130/1068 [05:50<41:48,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0386, 'learning_rate': 2.6348314606741574e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 140/1068 [06:17<41:45,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0368, 'learning_rate': 2.606741573033708e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 150/1068 [06:44<41:56,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0357, 'learning_rate': 2.5786516853932585e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 160/1068 [07:11<40:59,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0351, 'learning_rate': 2.5505617977528088e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 170/1068 [07:38<39:55,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0352, 'learning_rate': 2.52247191011236e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 180/1068 [08:04<39:27,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0356, 'learning_rate': 2.4943820224719103e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 190/1068 [08:32<40:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0355, 'learning_rate': 2.4662921348314606e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 200/1068 [08:59<39:27,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.034, 'learning_rate': 2.4382022471910114e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 210/1068 [09:26<38:55,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0347, 'learning_rate': 2.4101123595505617e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 220/1068 [09:54<38:29,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0353, 'learning_rate': 2.3820224719101125e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 230/1068 [10:22<38:41,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0363, 'learning_rate': 2.353932584269663e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 240/1068 [10:50<38:28,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0327, 'learning_rate': 2.3258426966292135e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 250/1068 [11:18<37:22,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.032, 'learning_rate': 2.297752808988764e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 260/1068 [11:45<36:57,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0339, 'learning_rate': 2.2696629213483146e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 270/1068 [12:13<36:43,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0324, 'learning_rate': 2.2415730337078654e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 280/1068 [12:41<36:04,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0335, 'learning_rate': 2.2134831460674157e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 290/1068 [13:09<35:48,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0357, 'learning_rate': 2.1853932584269665e-05, 'epoch': 0.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 300/1068 [13:37<36:17,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.033, 'learning_rate': 2.1573033707865168e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 310/1068 [14:05<34:54,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0325, 'learning_rate': 2.1292134831460672e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 320/1068 [14:32<34:38,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0306, 'learning_rate': 2.1011235955056183e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 330/1068 [15:00<33:57,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0317, 'learning_rate': 2.0730337078651686e-05, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 340/1068 [15:28<33:37,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.031, 'learning_rate': 2.044943820224719e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 350/1068 [15:55<33:04,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0315, 'learning_rate': 2.0168539325842697e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|███▎      | 356/1068 [16:37<26:38,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.029122376814484596, 'eval_runtime': 26.5461, 'eval_samples_per_second': 428.614, 'eval_steps_per_second': 13.411, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 360/1068 [16:52<1:08:00,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0323, 'learning_rate': 1.98876404494382e-05, 'epoch': 1.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 370/1068 [17:20<34:08,  2.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0298, 'learning_rate': 1.9606741573033708e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 380/1068 [17:48<32:35,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0309, 'learning_rate': 1.9325842696629215e-05, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 390/1068 [18:16<31:17,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0299, 'learning_rate': 1.904494382022472e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 400/1068 [18:44<31:04,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0304, 'learning_rate': 1.8764044943820223e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 410/1068 [19:11<29:53,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0293, 'learning_rate': 1.848314606741573e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 420/1068 [19:39<29:34,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0299, 'learning_rate': 1.8202247191011237e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 430/1068 [20:08<29:38,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0285, 'learning_rate': 1.792134831460674e-05, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 440/1068 [20:36<29:02,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0314, 'learning_rate': 1.7640449438202248e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 450/1068 [21:03<28:07,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.031, 'learning_rate': 1.7359550561797752e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 460/1068 [21:31<27:51,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0271, 'learning_rate': 1.7078651685393256e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 470/1068 [22:00<28:19,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0298, 'learning_rate': 1.6797752808988766e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 480/1068 [22:27<26:58,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0287, 'learning_rate': 1.651685393258427e-05, 'epoch': 1.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 490/1068 [22:56<26:57,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0288, 'learning_rate': 1.6235955056179774e-05, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 500/1068 [23:23<25:54,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0288, 'learning_rate': 1.595505617977528e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 510/1068 [23:52<26:03,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0274, 'learning_rate': 1.5674157303370788e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 520/1068 [24:21<26:09,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0283, 'learning_rate': 1.5393258426966292e-05, 'epoch': 1.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 530/1068 [24:49<25:11,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0301, 'learning_rate': 1.51123595505618e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 540/1068 [25:17<24:41,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0273, 'learning_rate': 1.4831460674157303e-05, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 550/1068 [25:46<24:36,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0284, 'learning_rate': 1.455056179775281e-05, 'epoch': 1.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 560/1068 [26:17<24:47,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0293, 'learning_rate': 1.4269662921348316e-05, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 570/1068 [26:46<24:19,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0264, 'learning_rate': 1.398876404494382e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 580/1068 [27:15<23:14,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0296, 'learning_rate': 1.3707865168539327e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 590/1068 [27:43<22:20,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0294, 'learning_rate': 1.3426966292134832e-05, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 600/1068 [28:11<22:12,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0286, 'learning_rate': 1.3146067415730338e-05, 'epoch': 1.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 610/1068 [28:41<21:55,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0272, 'learning_rate': 1.2865168539325843e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 620/1068 [29:10<21:12,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 1.258426966292135e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 630/1068 [29:38<20:25,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0282, 'learning_rate': 1.2303370786516854e-05, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 640/1068 [30:06<19:46,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.026, 'learning_rate': 1.202247191011236e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 650/1068 [30:34<19:18,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0277, 'learning_rate': 1.1741573033707867e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 660/1068 [31:02<19:11,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0285, 'learning_rate': 1.146067415730337e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 670/1068 [31:32<20:01,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0264, 'learning_rate': 1.1179775280898877e-05, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 680/1068 [32:00<18:17,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0263, 'learning_rate': 1.0898876404494383e-05, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 690/1068 [32:29<17:46,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0277, 'learning_rate': 1.0617977528089887e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 700/1068 [32:59<18:37,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0266, 'learning_rate': 1.0337078651685394e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 710/1068 [33:27<16:37,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0293, 'learning_rate': 1.00561797752809e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 67%|██████▋   | 712/1068 [33:58<13:30,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02724052406847477, 'eval_runtime': 27.7836, 'eval_samples_per_second': 409.523, 'eval_steps_per_second': 12.813, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 720/1068 [34:25<21:15,  3.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0246, 'learning_rate': 9.775280898876405e-06, 'epoch': 2.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 730/1068 [34:54<16:14,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0265, 'learning_rate': 9.49438202247191e-06, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 740/1068 [35:22<15:41,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0238, 'learning_rate': 9.213483146067416e-06, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 750/1068 [35:53<15:57,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0273, 'learning_rate': 8.932584269662921e-06, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 760/1068 [36:21<14:27,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.025, 'learning_rate': 8.651685393258427e-06, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 770/1068 [36:50<14:14,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.025, 'learning_rate': 8.370786516853934e-06, 'epoch': 2.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 780/1068 [37:20<14:08,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0252, 'learning_rate': 8.089887640449438e-06, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 790/1068 [37:52<15:35,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0253, 'learning_rate': 7.808988764044945e-06, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 800/1068 [38:20<12:45,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.026, 'learning_rate': 7.5280898876404495e-06, 'epoch': 2.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 810/1068 [38:49<12:28,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0247, 'learning_rate': 7.247191011235956e-06, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 820/1068 [39:18<11:45,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 6.966292134831461e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 830/1068 [39:49<11:34,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0268, 'learning_rate': 6.685393258426966e-06, 'epoch': 2.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 840/1068 [40:18<11:04,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.027, 'learning_rate': 6.404494382022472e-06, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 850/1068 [40:47<10:33,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 6.123595505617978e-06, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 860/1068 [41:15<09:51,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0239, 'learning_rate': 5.842696629213483e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 870/1068 [41:44<09:35,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0248, 'learning_rate': 5.5617977528089895e-06, 'epoch': 2.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 880/1068 [42:13<08:52,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.024, 'learning_rate': 5.280898876404495e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 890/1068 [42:41<08:20,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0239, 'learning_rate': 4.9999999999999996e-06, 'epoch': 2.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 900/1068 [43:12<08:22,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0234, 'learning_rate': 4.719101123595506e-06, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 910/1068 [43:42<07:41,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0254, 'learning_rate': 4.438202247191011e-06, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 920/1068 [44:10<06:52,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0249, 'learning_rate': 4.157303370786517e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 930/1068 [44:39<06:31,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0248, 'learning_rate': 3.876404494382023e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 940/1068 [45:08<06:01,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0241, 'learning_rate': 3.595505617977528e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 950/1068 [45:37<05:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0234, 'learning_rate': 3.314606741573034e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 960/1068 [46:05<04:55,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0267, 'learning_rate': 3.033707865168539e-06, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 970/1068 [46:34<04:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0261, 'learning_rate': 2.752808988764045e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 980/1068 [47:02<04:09,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0233, 'learning_rate': 2.4719101123595505e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 990/1068 [47:31<03:42,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.025, 'learning_rate': 2.191011235955056e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1000/1068 [48:00<03:10,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'learning_rate': 1.910112359550562e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1010/1068 [48:28<02:44,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0236, 'learning_rate': 1.6292134831460675e-06, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1020/1068 [48:56<02:16,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0213, 'learning_rate': 1.348314606741573e-06, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1030/1068 [49:26<01:53,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0243, 'learning_rate': 1.0674157303370785e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1040/1068 [49:54<01:20,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0257, 'learning_rate': 7.865168539325844e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1050/1068 [50:23<00:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0256, 'learning_rate': 5.056179775280899e-07, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1060/1068 [50:52<00:23,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.024, 'learning_rate': 2.247191011235955e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1068/1068 [51:41<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0243062861263752, 'eval_runtime': 27.3885, 'eval_samples_per_second': 415.43, 'eval_steps_per_second': 12.998, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [51:45<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3105.1956, 'train_samples_per_second': 43.968, 'train_steps_per_second': 0.344, 'train_loss': 0.030119813183385333, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 356/356 [00:27<00:00, 13.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0243062861263752,\n",
       " 'eval_runtime': 27.3871,\n",
       " 'eval_samples_per_second': 415.451,\n",
       " 'eval_steps_per_second': 12.999,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Specifiy the arguments for the trainer  \n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./results',          \n",
    "    num_train_epochs = 3,     \n",
    "    per_device_train_batch_size = 128,   \n",
    "    per_device_eval_batch_size = 32,   \n",
    "    weight_decay = 0.01,               \n",
    "    learning_rate = 3e-5,\n",
    "    logging_dir = './logs',\n",
    "    logging_steps = 10,        \n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end = True,     \n",
    "    #metric_for_best_model = 'rmse',    \n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    ") \n",
    "\n",
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,                         \n",
    "    args = training_args,                  \n",
    "    train_dataset = tokenized_datasets[\"train\"],         \n",
    "    eval_dataset = tokenized_datasets[\"test\"],          \n",
    "    #compute_metrics = compute_metrics,\n",
    "    data_collator = data_collator, \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Call the summary\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin/.cache\\huggingface\\modules\\transformers_modules\\zhihan1996\\DNABERT-2-117M\\1d020b803b871a976f5f3d5565f0eac8f2c7bb81\\bert_layers.py:125: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at zhihan1996/DNABERT-2-117M were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0495],\n",
      "        [ 0.0050],\n",
      "        [ 0.0346],\n",
      "        [ 0.1536],\n",
      "        [-0.0072]])\n",
      "tensor([[0.6034],\n",
      "        [0.5854],\n",
      "        [0.7205],\n",
      "        [0.1395],\n",
      "        [0.5100]])\n",
      "mse:  0.2381744  rmse:  0.48803115  mae:  0.440737  r2:  -4.579909511011868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    logits = logits[0]\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "\n",
    "    return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"smape\": smape}\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    modelpath,\n",
    "    cache_dir=None,\n",
    "    num_labels=1,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "#metric = evaluate.load(\"accuracy\")\n",
    "#model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    labels = batch[\"labels\"].reshape(-1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    \n",
    "    #calculate metrics\n",
    "\n",
    "    logits = outputs[\"logits\"]\n",
    "    \n",
    "    #use cpu to calculate metrics\n",
    "    logits = logits.cpu()\n",
    "    labels = labels.cpu()\n",
    "\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    #smape = 1/len(labels) * np.sum(2 * np.abs(logits-labels) / (np.abs(labels) + np.abs(logits))*100)\n",
    "    print(logits[:5])\n",
    "    print(labels[:5])\n",
    "\n",
    "    print(\"mse: \", mse, \" rmse: \", rmse, \" mae: \", mae, \" r2: \", r2)\n",
    "    break\n",
    "\n",
    "\n",
    "#metric.compute()\n",
    "\n",
    "#trained\n",
    "\n",
    "# tensor([[0.5489],\n",
    "#         [0.3944],\n",
    "#         [0.7925],\n",
    "#         [0.4906],\n",
    "#         [0.5423]])\n",
    "# tensor([[0.6034],\n",
    "#         [0.5854],\n",
    "#         [0.7205],\n",
    "#         [0.1395],\n",
    "#         [0.5100]])\n",
    "# mse:  0.031777926  rmse:  0.17826363  mae:  0.13696145  r2:  0.25551206762590795\n",
    "\n",
    "#untrained\n",
    "\n",
    "# tensor([[-0.0495],\n",
    "#         [ 0.0050],\n",
    "#         [ 0.0346],\n",
    "#         [ 0.1536],\n",
    "#         [-0.0072]])\n",
    "# tensor([[0.6034],\n",
    "#         [0.5854],\n",
    "#         [0.7205],\n",
    "#         [0.1395],\n",
    "#         [0.5100]])\n",
    "# mse:  0.2381744  rmse:  0.48803115  mae:  0.440737  r2:  -4.579909511011868"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnabert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
