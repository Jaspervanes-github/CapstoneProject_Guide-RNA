{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\AppData\\Roaming\\Python\\Python36\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "c:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\keras\\models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from prediction_util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGGTGAGCAAGGGCGAGGAGCTGTTCACCGGGGTGGTGCCCATCCTGGTCGAGCTGGACGGCGACGTAAACGGCCACAAGTTCAGCGTGTCCGGCGAGGGCGAGGGCGATGCCACCTACGGCAAGCTGACCCTGAAGTTCATCTGCACCACCGGCAAGCTGCCCGTGCCCTGGCCCACCCTCGTGACCACCCTGACCTACGGCGTGCAGTGCTTCAGCCGCTACCCCGACCACATGAAGCAGCACGACTTCTTCAAGTCCGCCATGCCCGAAGGCTACGTCCAGGAGCGCACCATCTTCTTCAAGGACGACGGCAACTACAAGACCCGCGCCGAGGTGAAGTTCGAGGGCGACACCCTGGTGAACCGCATCGAGCTGAAGGGCATCGACTTCAAGGAGGACGGCAACATCCTGGGGCACAAGCTGGAGTACAACTACAACAGCCACAACGTCTATATCATGGCCGACAAGCAGAAGAACGGCATCAAGGTGAACTTCAAGATCCGCCACAACATCGAGGACGGCAGCGTGCAGCTCGCCGACCACTACCAGCAGAACACCCCCATCGGCGACGGCCCCGTGCTGCTGCCCGACAACCACTACCTGAGCACCCAGTCCGCCCTGAGCAAAGACCCCAACGAGAAGCGCGATCACATGGTCCTGCTGGAGTTCGTGACCGCCGCCGGGATCACTCTCGGCATGGACGAGCTGTACAAGTAA\n",
      "Empty DataFrame\n",
      "Columns: [Strand, Cut_Pos, 21mer, PAM]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "should only have sequences of a single length, but found 0: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6842b7d4688b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0meffciency_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seq'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'esp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36meffciency_predict\u001b[1;34m(sequence, model_type)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_biofeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embedding_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;31m# print(\"After embedding\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36mget_embedding_data\u001b[1;34m(data, feature_options)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mfeature_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'order'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m#generating biofeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_feature\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mlst_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mfeat_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlst_features\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36mmy_feature\u001b[1;34m(df_model, feature_options)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmy_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mfeature_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'order'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mfeature_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeaturize_data\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate_feature_sets\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfeature_sets\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\feature_util.py\u001b[0m in \u001b[0;36mfeaturize_data\u001b[1;34m(data, feature_options, length_audit, quiet)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     assert num_lengths == 1, \"should only have sequences of a single length, but found %s: %s\" % (\n\u001b[1;32m---> 63\u001b[1;33m         num_lengths, str( unique_lengths ))\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: should only have sequences of a single length, but found 0: []"
     ]
    }
   ],
   "source": [
    "#WNT1(NM_005430.3) DNA sequence for example\n",
    "seq = '''Atggtgagcaagggcgaggagctgttcaccggggtggtgcccatcctggtcgagctggacggcgacgtaaacggccacaagttcagcgtgtccggcgagggcgagggcgatgccacctacggcaagctgaccctgaagttcatctgcaccaccggcaagctgcccgtgccctggcccaccctcgtgaccaccctgacctacggcgtgcagtgcttcagccgctaccccgaccacatgaagcagcacgacttcttcaagtccgccatgcccgaaggctacgtccaggagcgcaccatcttcttcaaggacgacggcaactacaagacccgcgccgaggtgaagttcgagggcgacaccctggtgaaccgcatcgagctgaagggcatcgacttcaaggaggacggcaacatcctggggcacaagctggagtacaactacaacagccacaacgtctatatcatggccgacaagcagaagaacggcatcaaggtgaacttcaagatccgccacaacatcgaggacggcagcgtgcagctcgccgaccactaccagcagaacacccccatcggcgacggccccgtgctgctgcccgacaaccactacctgagcacccagtccgccctgagcaaagaccccaacgagaagcgcgatcacatggtcctgctggagttcgtgaccgccgccgggatcactctcggcatggacgagctgtacaagtaa'''\n",
    "\n",
    "#make all capital\n",
    "seq = seq.upper()\n",
    "print(seq)\n",
    "effciency_predict('seq','esp')\n",
    "\n",
    "\n",
    "enzyme = 'esp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGTGTGACTACCGGCGGCGCGG\n",
      "  Strand  Cut_Pos                  21mer  PAM\n",
      "0      +       17  ACGTGTGACTACCGGCGGCGC  CGG\n",
      "Constructing sencondary structure features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "X_1= [[1 2 4 5 3 5 3 5 2 4 3 2 4 4 5 5 4 5 5 4 5 4]]\n",
      "inputs  [array([[1, 2, 4, 5, 3, 5, 3, 5, 2, 4, 3, 2, 4, 4, 5, 5, 4, 5, 5, 4, 5, 4]]), array([[  0.        ,  -1.2       , -29.4       , -19.1       ,\n",
      "          1.        ,   0.        ,  14.        ,  64.21331622,\n",
      "         12.11039503,  14.56163309, -52.36053107]])]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 22)\n",
      "(1, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>17</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACGTGTGACTACCGGCGGCG</td>\n",
       "      <td>0.28913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
       "0      0      +       17  CGG  ACGTGTGACTACCGGCGGCG     0.28913"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ACGTGTGACTACCGGCGGCGCGG\")\n",
    "effciency_predict('ACGTGTGACTACCGGCGGCGCGG','esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Strand  Cut_Pos                  21mer  PAM\n",
      "0      +       17  ACGTGTGACTACCGGCGGCGC  CGG\n",
      "Constructing sencondary structure features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "X_1= [[1 2 4 5 3 5 3 5 2 4 3 2 4 4 5 5 4 5 5 4 5 4]]\n",
      "inputs  [array([[1, 2, 4, 5, 3, 5, 3, 5, 2, 4, 3, 2, 4, 4, 5, 5, 4, 5, 5, 4, 5, 4]]), array([[  0.        ,  -1.2       , -29.4       , -19.1       ,\n",
      "          1.        ,   0.        ,  14.        ,  64.21331622,\n",
      "         12.11039503,  14.56163309, -52.36053107]])]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 22)\n",
      "(1, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>17</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACGTGTGACTACCGGCGGCG</td>\n",
       "      <td>0.62073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
       "0      0      +       17  CGG  ACGTGTGACTACCGGCGGCG     0.62073"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzyme = 'wt_u6'\n",
    "effciency_predict('ACGTGTGACTACCGGCGGCGCGG',enzyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Strand  Cut_Pos                  21mer  PAM\n",
      "0      +       17  ACGTGTGACTACCGGCGGCGC  CGG\n",
      "Constructing sencondary structure features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-1\n",
      "N-None,N2-1\n",
      "X_1= [[1 2 4 5 3 5 3 5 2 4 3 2 4 4 5 5 4 5 5 4 5 4]]\n",
      "inputs  [array([[1, 2, 4, 5, 3, 5, 3, 5, 2, 4, 3, 2, 4, 4, 5, 5, 4, 5, 5, 4, 5, 4]]), array([[  0.        ,  -1.2       , -29.4       , -19.1       ,\n",
      "          1.        ,   0.        ,  14.        ,  64.21331622,\n",
      "         12.11039503,  14.56163309, -52.36053107]])]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 22)\n",
      "(1, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "      <td>17</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ACGTGTGACTACCGGCGGCG</td>\n",
       "      <td>0.54135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
       "0      0      +       17  CGG  ACGTGTGACTACCGGCGGCG     0.54135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enzyme = 'wt_t7'\n",
    "effciency_predict('ACGTGTGACTACCGGCGGCGCGG',enzyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Strand, Cut_Pos, 21mer, PAM]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "should only have sequences of a single length, but found 0: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-52174d97be14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meffciency_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menzyme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36meffciency_predict\u001b[1;34m(sequence, model_type)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_biofeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embedding_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;31m# print(\"After embedding\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36mget_embedding_data\u001b[1;34m(data, feature_options)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mfeature_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'order'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m#generating biofeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_feature\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mlst_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mfeat_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlst_features\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\prediction_util.py\u001b[0m in \u001b[0;36mmy_feature\u001b[1;34m(df_model, feature_options)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmy_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mfeature_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'order'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mfeature_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeaturize_data\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_options\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate_feature_sets\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfeature_sets\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimsum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\CapstoneProject_Guide-RNA\\src\\DeepHF-master_Robin_Edited\\feature_util.py\u001b[0m in \u001b[0;36mfeaturize_data\u001b[1;34m(data, feature_options, length_audit, quiet)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     assert num_lengths == 1, \"should only have sequences of a single length, but found %s: %s\" % (\n\u001b[1;32m---> 63\u001b[1;33m         num_lengths, str( unique_lengths ))\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: should only have sequences of a single length, but found 0: []"
     ]
    }
   ],
   "source": [
    "result = effciency_predict(seq, enzyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 441 entries, 438 to 351\n",
      "Data columns (total 7 columns):\n",
      "index         441 non-null int64\n",
      "Strand        441 non-null object\n",
      "Cut_Pos       441 non-null int64\n",
      "21mer         441 non-null object\n",
      "PAM           441 non-null object\n",
      "gRNA_Seq      441 non-null object\n",
      "Efficiency    441 non-null float32\n",
      "dtypes: float32(1), int64(2), object(4)\n",
      "memory usage: 25.8+ KB\n"
     ]
    }
   ],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Cut_Pos</th>\n",
       "      <th>21mer</th>\n",
       "      <th>PAM</th>\n",
       "      <th>gRNA_Seq</th>\n",
       "      <th>Efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>438</td>\n",
       "      <td>-</td>\n",
       "      <td>2268</td>\n",
       "      <td>GTGGGCTGAGGCGGCCACGGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GTGGGCTGAGGCGGCCACGG</td>\n",
       "      <td>0.80088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>-</td>\n",
       "      <td>2168</td>\n",
       "      <td>GGGACGGGACGCGGCGGTGGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGGACGGGACGCGGCGGTGG</td>\n",
       "      <td>0.75014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>-</td>\n",
       "      <td>950</td>\n",
       "      <td>CTCGAGGAGAGCGTTCCTGGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTCGAGGAGAGCGTTCCTGG</td>\n",
       "      <td>0.73312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>-</td>\n",
       "      <td>882</td>\n",
       "      <td>GTGACTGGAGGTACTCGGGTG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GTGACTGGAGGTACTCGGGT</td>\n",
       "      <td>0.73055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>+</td>\n",
       "      <td>757</td>\n",
       "      <td>CCGGGAGTTCGTGGACTCCGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CCGGGAGTTCGTGGACTCCG</td>\n",
       "      <td>0.71973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>212</td>\n",
       "      <td>-</td>\n",
       "      <td>338</td>\n",
       "      <td>AAGGGGTAGGAGGTGGCCCAG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>AAGGGGTAGGAGGTGGCCCA</td>\n",
       "      <td>0.71115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>+</td>\n",
       "      <td>695</td>\n",
       "      <td>GGGGGCCCCGACTGGCACTGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGGGGCCCCGACTGGCACTG</td>\n",
       "      <td>0.70952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>+</td>\n",
       "      <td>1607</td>\n",
       "      <td>CCAGGAGGTGAGAGAAGGATG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CCAGGAGGTGAGAGAAGGAT</td>\n",
       "      <td>0.70745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>416</td>\n",
       "      <td>-</td>\n",
       "      <td>2162</td>\n",
       "      <td>GACGGTGGGACGGGACGCGGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GACGGTGGGACGGGACGCGG</td>\n",
       "      <td>0.70487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>-</td>\n",
       "      <td>603</td>\n",
       "      <td>GGGGAAGAAGAGAGGCAGAGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGGGAAGAAGAGAGGCAGAG</td>\n",
       "      <td>0.70371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>419</td>\n",
       "      <td>-</td>\n",
       "      <td>2174</td>\n",
       "      <td>GGACGCGGCGGTGGCGGCAGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGACGCGGCGGTGGCGGCAG</td>\n",
       "      <td>0.69448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>-</td>\n",
       "      <td>40</td>\n",
       "      <td>AGAGGAAGATGCTACACTGGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AGAGGAAGATGCTACACTGG</td>\n",
       "      <td>0.69077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>-</td>\n",
       "      <td>190</td>\n",
       "      <td>GAGGGATTGGGTTGGGTTGGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GAGGGATTGGGTTGGGTTGG</td>\n",
       "      <td>0.68981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>439</td>\n",
       "      <td>-</td>\n",
       "      <td>2269</td>\n",
       "      <td>TGGGCTGAGGCGGCCACGGCG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TGGGCTGAGGCGGCCACGGC</td>\n",
       "      <td>0.68906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>-</td>\n",
       "      <td>1034</td>\n",
       "      <td>AGCTGACGTGGCAGCACCAGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AGCTGACGTGGCAGCACCAG</td>\n",
       "      <td>0.68627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>+</td>\n",
       "      <td>696</td>\n",
       "      <td>GGGGCCCCGACTGGCACTGGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGGGCCCCGACTGGCACTGG</td>\n",
       "      <td>0.68390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>-</td>\n",
       "      <td>735</td>\n",
       "      <td>GGGTCTCCCGCGGAGAGGGAG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGGTCTCCCGCGGAGAGGGA</td>\n",
       "      <td>0.68187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>-</td>\n",
       "      <td>393</td>\n",
       "      <td>GACAGAGACTGGGAGAATGGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GACAGAGACTGGGAGAATGG</td>\n",
       "      <td>0.68162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>-</td>\n",
       "      <td>870</td>\n",
       "      <td>ACCGCGGGGAGTGTGACTGGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>ACCGCGGGGAGTGTGACTGG</td>\n",
       "      <td>0.68139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>208</td>\n",
       "      <td>-</td>\n",
       "      <td>325</td>\n",
       "      <td>GAGGCAGGACAGGAAGGGGTA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GAGGCAGGACAGGAAGGGGT</td>\n",
       "      <td>0.68055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>+</td>\n",
       "      <td>1623</td>\n",
       "      <td>GGATGGGTCCCCTCCGCCATG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGATGGGTCCCCTCCGCCAT</td>\n",
       "      <td>0.67896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>-</td>\n",
       "      <td>1768</td>\n",
       "      <td>AGGTGGGGCCCTGGAGCAGTG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>AGGTGGGGCCCTGGAGCAGT</td>\n",
       "      <td>0.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>292</td>\n",
       "      <td>-</td>\n",
       "      <td>856</td>\n",
       "      <td>TGGGATGCGTATGAACCGCGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TGGGATGCGTATGAACCGCG</td>\n",
       "      <td>0.67191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>-</td>\n",
       "      <td>927</td>\n",
       "      <td>TAGCGAGTCTGTTTGGGGGAG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TAGCGAGTCTGTTTGGGGGA</td>\n",
       "      <td>0.67158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>429</td>\n",
       "      <td>-</td>\n",
       "      <td>2229</td>\n",
       "      <td>GGGGCGGGCGGCGGACAGCAT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGGGCGGGCGGCGGACAGCA</td>\n",
       "      <td>0.66905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>417</td>\n",
       "      <td>-</td>\n",
       "      <td>2165</td>\n",
       "      <td>GGTGGGACGGGACGCGGCGGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGTGGGACGGGACGCGGCGG</td>\n",
       "      <td>0.66884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>+</td>\n",
       "      <td>677</td>\n",
       "      <td>TACCGGCGGCGCGGCCCCGGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TACCGGCGGCGCGGCCCCGG</td>\n",
       "      <td>0.66746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>-</td>\n",
       "      <td>341</td>\n",
       "      <td>GGGTAGGAGGTGGCCCAGGGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGGTAGGAGGTGGCCCAGGG</td>\n",
       "      <td>0.66718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>384</td>\n",
       "      <td>-</td>\n",
       "      <td>1781</td>\n",
       "      <td>GAGCAGTGGGACAGTTCCAGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GAGCAGTGGGACAGTTCCAG</td>\n",
       "      <td>0.66638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>329</td>\n",
       "      <td>-</td>\n",
       "      <td>1226</td>\n",
       "      <td>CGAAGTAGACGAGGTCGTGGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CGAAGTAGACGAGGTCGTGG</td>\n",
       "      <td>0.66594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>+</td>\n",
       "      <td>422</td>\n",
       "      <td>CGTCTGATACGCCAAAATCCG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CGTCTGATACGCCAAAATCC</td>\n",
       "      <td>0.18281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>+</td>\n",
       "      <td>1713</td>\n",
       "      <td>CCTTTGTCCTGCGTTTTCTCC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>CCTTTGTCCTGCGTTTTCTC</td>\n",
       "      <td>0.18250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>+</td>\n",
       "      <td>1589</td>\n",
       "      <td>GCACTGCCCCCTGCTTGGCCA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GCACTGCCCCCTGCTTGGCC</td>\n",
       "      <td>0.17686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>104</td>\n",
       "      <td>+</td>\n",
       "      <td>1159</td>\n",
       "      <td>TAACAGCTCGTCGCCCGCGCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TAACAGCTCGTCGCCCGCGC</td>\n",
       "      <td>0.17342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>-</td>\n",
       "      <td>2091</td>\n",
       "      <td>CCAGAGCCCCATGGCCTGCCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>CCAGAGCCCCATGGCCTGCC</td>\n",
       "      <td>0.17211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>+</td>\n",
       "      <td>250</td>\n",
       "      <td>TGCTACGCTGCTGCTGGCGCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TGCTACGCTGCTGCTGGCGC</td>\n",
       "      <td>0.16274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>+</td>\n",
       "      <td>734</td>\n",
       "      <td>ATTGACTTCGGCCGCCTCTTC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>ATTGACTTCGGCCGCCTCTT</td>\n",
       "      <td>0.16159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>-</td>\n",
       "      <td>1217</td>\n",
       "      <td>GCGATTTCTCGAAGTAGACGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GCGATTTCTCGAAGTAGACG</td>\n",
       "      <td>0.15219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>+</td>\n",
       "      <td>891</td>\n",
       "      <td>CATGCACGGTGCGCACGTGCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>CATGCACGGTGCGCACGTGC</td>\n",
       "      <td>0.14429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>+</td>\n",
       "      <td>1188</td>\n",
       "      <td>GCGAGCTGCTCTGCTGCGGCA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GCGAGCTGCTCTGCTGCGGC</td>\n",
       "      <td>0.14217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>400</td>\n",
       "      <td>-</td>\n",
       "      <td>2006</td>\n",
       "      <td>GGCCACTGCTGTTGGCAGCCA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGCCACTGCTGTTGGCAGCC</td>\n",
       "      <td>0.12122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>-</td>\n",
       "      <td>475</td>\n",
       "      <td>TAACCTCCTGCTTCAGCTACA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TAACCTCCTGCTTCAGCTAC</td>\n",
       "      <td>0.12063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>+</td>\n",
       "      <td>1584</td>\n",
       "      <td>TTGTTGCACTGCCCCCTGCTT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TTGTTGCACTGCCCCCTGCT</td>\n",
       "      <td>0.12047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>+</td>\n",
       "      <td>594</td>\n",
       "      <td>TCTTCGCTATCACCTCCGCCG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>TCTTCGCTATCACCTCCGCC</td>\n",
       "      <td>0.11656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>+</td>\n",
       "      <td>1108</td>\n",
       "      <td>CTGCACGTACAGCGGACGCCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>CTGCACGTACAGCGGACGCC</td>\n",
       "      <td>0.11125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>-</td>\n",
       "      <td>797</td>\n",
       "      <td>TTCATGCCGCCCCAGGCAAGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TTCATGCCGCCCCAGGCAAG</td>\n",
       "      <td>0.10493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>+</td>\n",
       "      <td>2006</td>\n",
       "      <td>AAATAATTTGCACTGAAACGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AAATAATTTGCACTGAAACG</td>\n",
       "      <td>0.10493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>-</td>\n",
       "      <td>303</td>\n",
       "      <td>AAATTATTTACACACTGATGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>AAATTATTTACACACTGATG</td>\n",
       "      <td>0.08159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>+</td>\n",
       "      <td>841</td>\n",
       "      <td>CGTATTCTCCGAGATGCGCCA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>CGTATTCTCCGAGATGCGCC</td>\n",
       "      <td>0.07849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>+</td>\n",
       "      <td>1714</td>\n",
       "      <td>CTTTGTCCTGCGTTTTCTCCG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>CTTTGTCCTGCGTTTTCTCC</td>\n",
       "      <td>0.07583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>427</td>\n",
       "      <td>-</td>\n",
       "      <td>2217</td>\n",
       "      <td>TTAACAACCCTGGGGGCGGGC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>TTAACAACCCTGGGGGCGGG</td>\n",
       "      <td>0.01434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>+</td>\n",
       "      <td>244</td>\n",
       "      <td>GGTTTCTGCTACGCTGCTGCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGTTTCTGCTACGCTGCTGC</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>164</td>\n",
       "      <td>+</td>\n",
       "      <td>2058</td>\n",
       "      <td>ATAAAACTATTTATTGTGCTG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>ATAAAACTATTTATTGTGCT</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>+</td>\n",
       "      <td>2069</td>\n",
       "      <td>TATTGTGCTGGGTCCCAGCCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TATTGTGCTGGGTCCCAGCC</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>-</td>\n",
       "      <td>258</td>\n",
       "      <td>ATTTACAACATCCAAACTCGT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>ATTTACAACATCCAAACTCG</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>+</td>\n",
       "      <td>2143</td>\n",
       "      <td>TTTCTCCCTGCAGCCTTTTCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TTTCTCCCTGCAGCCTTTTC</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>167</td>\n",
       "      <td>+</td>\n",
       "      <td>2188</td>\n",
       "      <td>TCAAAGATGCGTTTGCCTCCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>TCAAAGATGCGTTTGCCTCC</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>202</td>\n",
       "      <td>-</td>\n",
       "      <td>306</td>\n",
       "      <td>TTATTTACACACTGATGAGGA</td>\n",
       "      <td>AGG</td>\n",
       "      <td>TTATTTACACACTGATGAGG</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>+</td>\n",
       "      <td>2057</td>\n",
       "      <td>AATAAAACTATTTATTGTGCT</td>\n",
       "      <td>TGG</td>\n",
       "      <td>AATAAAACTATTTATTGTGC</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>351</td>\n",
       "      <td>-</td>\n",
       "      <td>1446</td>\n",
       "      <td>CTTGCACTCCTGGCGCATCTC</td>\n",
       "      <td>CGG</td>\n",
       "      <td>CTTGCACTCCTGGCGCATCT</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index Strand  Cut_Pos                  21mer  PAM              gRNA_Seq  \\\n",
       "438    438      -     2268  GTGGGCTGAGGCGGCCACGGC  CGG  GTGGGCTGAGGCGGCCACGG   \n",
       "418    418      -     2168  GGGACGGGACGCGGCGGTGGC  CGG  GGGACGGGACGCGGCGGTGG   \n",
       "311    311      -      950  CTCGAGGAGAGCGTTCCTGGG  GGG  CTCGAGGAGAGCGTTCCTGG   \n",
       "298    298      -      882  GTGACTGGAGGTACTCGGGTG  GGG  GTGACTGGAGGTACTCGGGT   \n",
       "71      71      +      757  CCGGGAGTTCGTGGACTCCGG  GGG  CCGGGAGTTCGTGGACTCCG   \n",
       "212    212      -      338  AAGGGGTAGGAGGTGGCCCAG  GGG  AAGGGGTAGGAGGTGGCCCA   \n",
       "60      60      +      695  GGGGGCCCCGACTGGCACTGG  GGG  GGGGGCCCCGACTGGCACTG   \n",
       "132    132      +     1607  CCAGGAGGTGAGAGAAGGATG  GGG  CCAGGAGGTGAGAGAAGGAT   \n",
       "416    416      -     2162  GACGGTGGGACGGGACGCGGC  CGG  GACGGTGGGACGGGACGCGG   \n",
       "247    247      -      603  GGGGAAGAAGAGAGGCAGAGA  AGG  GGGGAAGAAGAGAGGCAGAG   \n",
       "419    419      -     2174  GGACGCGGCGGTGGCGGCAGT  TGG  GGACGCGGCGGTGGCGGCAG   \n",
       "171    171      -       40  AGAGGAAGATGCTACACTGGT  TGG  AGAGGAAGATGCTACACTGG   \n",
       "195    195      -      190  GAGGGATTGGGTTGGGTTGGA  AGG  GAGGGATTGGGTTGGGTTGG   \n",
       "439    439      -     2269  TGGGCTGAGGCGGCCACGGCG  GGG  TGGGCTGAGGCGGCCACGGC   \n",
       "314    314      -     1034  AGCTGACGTGGCAGCACCAGT  TGG  AGCTGACGTGGCAGCACCAG   \n",
       "61      61      +      696  GGGGCCCCGACTGGCACTGGG  GGG  GGGGCCCCGACTGGCACTGG   \n",
       "269    269      -      735  GGGTCTCCCGCGGAGAGGGAG  GGG  GGGTCTCCCGCGGAGAGGGA   \n",
       "221    221      -      393  GACAGAGACTGGGAGAATGGG  GGG  GACAGAGACTGGGAGAATGG   \n",
       "294    294      -      870  ACCGCGGGGAGTGTGACTGGA  AGG  ACCGCGGGGAGTGTGACTGG   \n",
       "208    208      -      325  GAGGCAGGACAGGAAGGGGTA  AGG  GAGGCAGGACAGGAAGGGGT   \n",
       "134    134      +     1623  GGATGGGTCCCCTCCGCCATG  GGG  GGATGGGTCCCCTCCGCCAT   \n",
       "383    383      -     1768  AGGTGGGGCCCTGGAGCAGTG  GGG  AGGTGGGGCCCTGGAGCAGT   \n",
       "292    292      -      856  TGGGATGCGTATGAACCGCGG  GGG  TGGGATGCGTATGAACCGCG   \n",
       "306    306      -      927  TAGCGAGTCTGTTTGGGGGAG  GGG  TAGCGAGTCTGTTTGGGGGA   \n",
       "429    429      -     2229  GGGGCGGGCGGCGGACAGCAT  TGG  GGGGCGGGCGGCGGACAGCA   \n",
       "417    417      -     2165  GGTGGGACGGGACGCGGCGGT  TGG  GGTGGGACGGGACGCGGCGG   \n",
       "56      56      +      677  TACCGGCGGCGCGGCCCCGGG  GGG  TACCGGCGGCGCGGCCCCGG   \n",
       "213    213      -      341  GGGTAGGAGGTGGCCCAGGGA  AGG  GGGTAGGAGGTGGCCCAGGG   \n",
       "384    384      -     1781  GAGCAGTGGGACAGTTCCAGC  CGG  GAGCAGTGGGACAGTTCCAG   \n",
       "329    329      -     1226  CGAAGTAGACGAGGTCGTGGG  GGG  CGAAGTAGACGAGGTCGTGG   \n",
       "..     ...    ...      ...                    ...  ...                   ...   \n",
       "29      29      +      422  CGTCTGATACGCCAAAATCCG  GGG  CGTCTGATACGCCAAAATCC   \n",
       "138    138      +     1713  CCTTTGTCCTGCGTTTTCTCC  CGG  CCTTTGTCCTGCGTTTTCTC   \n",
       "128    128      +     1589  GCACTGCCCCCTGCTTGGCCA  AGG  GCACTGCCCCCTGCTTGGCC   \n",
       "104    104      +     1159  TAACAGCTCGTCGCCCGCGCT  TGG  TAACAGCTCGTCGCCCGCGC   \n",
       "407    407      -     2091  CCAGAGCCCCATGGCCTGCCT  TGG  CCAGAGCCCCATGGCCTGCC   \n",
       "19      19      +      250  TGCTACGCTGCTGCTGGCGCT  TGG  TGCTACGCTGCTGCTGGCGC   \n",
       "65      65      +      734  ATTGACTTCGGCCGCCTCTTC  CGG  ATTGACTTCGGCCGCCTCTT   \n",
       "325    325      -     1217  GCGATTTCTCGAAGTAGACGA  AGG  GCGATTTCTCGAAGTAGACG   \n",
       "84      84      +      891  CATGCACGGTGCGCACGTGCT  TGG  CATGCACGGTGCGCACGTGC   \n",
       "107    107      +     1188  GCGAGCTGCTCTGCTGCGGCA  AGG  GCGAGCTGCTCTGCTGCGGC   \n",
       "400    400      -     2006  GGCCACTGCTGTTGGCAGCCA  AGG  GGCCACTGCTGTTGGCAGCC   \n",
       "223    223      -      475  TAACCTCCTGCTTCAGCTACA  AGG  TAACCTCCTGCTTCAGCTAC   \n",
       "127    127      +     1584  TTGTTGCACTGCCCCCTGCTT  TGG  TTGTTGCACTGCCCCCTGCT   \n",
       "45      45      +      594  TCTTCGCTATCACCTCCGCCG  GGG  TCTTCGCTATCACCTCCGCC   \n",
       "98      98      +     1108  CTGCACGTACAGCGGACGCCT  TGG  CTGCACGTACAGCGGACGCC   \n",
       "281    281      -      797  TTCATGCCGCCCCAGGCAAGT  TGG  TTCATGCCGCCCCAGGCAAG   \n",
       "161    161      +     2006  AAATAATTTGCACTGAAACGT  TGG  AAATAATTTGCACTGAAACG   \n",
       "201    201      -      303  AAATTATTTACACACTGATGA  AGG  AAATTATTTACACACTGATG   \n",
       "79      79      +      841  CGTATTCTCCGAGATGCGCCA  AGG  CGTATTCTCCGAGATGCGCC   \n",
       "139    139      +     1714  CTTTGTCCTGCGTTTTCTCCG  GGG  CTTTGTCCTGCGTTTTCTCC   \n",
       "427    427      -     2217  TTAACAACCCTGGGGGCGGGC  CGG  TTAACAACCCTGGGGGCGGG   \n",
       "18      18      +      244  GGTTTCTGCTACGCTGCTGCT  TGG  GGTTTCTGCTACGCTGCTGC   \n",
       "164    164      +     2058  ATAAAACTATTTATTGTGCTG  GGG  ATAAAACTATTTATTGTGCT   \n",
       "165    165      +     2069  TATTGTGCTGGGTCCCAGCCT  TGG  TATTGTGCTGGGTCCCAGCC   \n",
       "200    200      -      258  ATTTACAACATCCAAACTCGT  TGG  ATTTACAACATCCAAACTCG   \n",
       "166    166      +     2143  TTTCTCCCTGCAGCCTTTTCT  TGG  TTTCTCCCTGCAGCCTTTTC   \n",
       "167    167      +     2188  TCAAAGATGCGTTTGCCTCCT  TGG  TCAAAGATGCGTTTGCCTCC   \n",
       "202    202      -      306  TTATTTACACACTGATGAGGA  AGG  TTATTTACACACTGATGAGG   \n",
       "163    163      +     2057  AATAAAACTATTTATTGTGCT  TGG  AATAAAACTATTTATTGTGC   \n",
       "351    351      -     1446  CTTGCACTCCTGGCGCATCTC  CGG  CTTGCACTCCTGGCGCATCT   \n",
       "\n",
       "     Efficiency  \n",
       "438     0.80088  \n",
       "418     0.75014  \n",
       "311     0.73312  \n",
       "298     0.73055  \n",
       "71      0.71973  \n",
       "212     0.71115  \n",
       "60      0.70952  \n",
       "132     0.70745  \n",
       "416     0.70487  \n",
       "247     0.70371  \n",
       "419     0.69448  \n",
       "171     0.69077  \n",
       "195     0.68981  \n",
       "439     0.68906  \n",
       "314     0.68627  \n",
       "61      0.68390  \n",
       "269     0.68187  \n",
       "221     0.68162  \n",
       "294     0.68139  \n",
       "208     0.68055  \n",
       "134     0.67896  \n",
       "383     0.67466  \n",
       "292     0.67191  \n",
       "306     0.67158  \n",
       "429     0.66905  \n",
       "417     0.66884  \n",
       "56      0.66746  \n",
       "213     0.66718  \n",
       "384     0.66638  \n",
       "329     0.66594  \n",
       "..          ...  \n",
       "29      0.18281  \n",
       "138     0.18250  \n",
       "128     0.17686  \n",
       "104     0.17342  \n",
       "407     0.17211  \n",
       "19      0.16274  \n",
       "65      0.16159  \n",
       "325     0.15219  \n",
       "84      0.14429  \n",
       "107     0.14217  \n",
       "400     0.12122  \n",
       "223     0.12063  \n",
       "127     0.12047  \n",
       "45      0.11656  \n",
       "98      0.11125  \n",
       "281     0.10493  \n",
       "161     0.10493  \n",
       "201     0.08159  \n",
       "79      0.07849  \n",
       "139     0.07583  \n",
       "427     0.01434  \n",
       "18      0.00000  \n",
       "164     0.00000  \n",
       "165     0.00000  \n",
       "200     0.00000  \n",
       "166     0.00000  \n",
       "167     0.00000  \n",
       "202     0.00000  \n",
       "163     0.00000  \n",
       "351     0.00000  \n",
       "\n",
       "[441 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\keras\\models.py:318: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCGGTGCCGCCCGCCGTGGCCGCCTCAGCCCACCAGCCGGGACCGCGAGCCATGCTGTCCGCCGCCCGCCCCCAGGGTTGTTAAAGCCAGACTGCGAACTCTCGCCACTGCCGCCACCGCCGCGTCCCGTCCCACCGTCGCGGGCAACAACCAAAGTCGCCGCAACTGCAGCACAGAGCGGGCAAAGCCAGGCAGGCCATGGGGCTCTGGGCGCTGTTGCCTGGCTGGGTTTCTGCTACGCTGCTGCTGGCGCTGGCCGCTCTGCCCGCAGCCCTGGCTGCCAACAGCAGTGGCCGATGGTGGGGTATTGTGAACGTAGCCTCCTCCACGAACCTGCTTACAGACTCCAAGAGTCTGCAACTGGTACTCGAGCCCAGTCTGCAGCTGTTGAGCCGCAAACAGCGGCGTCTGATACGCCAAAATCCGGGGATCCTGCACAGCGTGAGTGGGGGGCTGCAGAGTGCCGTGCGCGAGTGCAAGTGGCAGTTCCGGAATCGCCGCTGGAACTGTCCCACTGCTCCAGGGCCCCACCTCTTCGGCAAGATCGTCAACCGAGGCTGTCGAGAAACGGCGTTTATCTTCGCTATCACCTCCGCCGGGGTCACCCATTCGGTGGCGCGCTCCTGCTCAGAAGGTTCCATCGAATCCTGCACGTGTGACTACCGGCGGCGCGGCCCCGGGGGCCCCGACTGGCACTGGGGGGGCTGCAGCGACAACATTGACTTCGGCCGCCTCTTCGGCCGGGAGTTCGTGGACTCCGGGGAGAAGGGGCGGGACCTGCGCTTCCTCATGAACCTTCACAACAACGAGGCAGGCCGTACGACCGTATTCTCCGAGATGCGCCAGGAGTGCAAGTGCCACGGGATGTCCGGCTCATGCACGGTGCGCACGTGCTGGATGCGGCTGCCCACGCTGCGCGCCGTGGGCGATGTGCTGCGCGACCGCTTCGACGGCGCCTCGCGCGTCCTGTACGGCAACCGCGGCAGCAACCGCGCTTCGCGGGCGGAGCTGCTGCGCCTGGAGCCGGAAGACCCGGCCCACAAACCGCCCTCCCCCCACGACCTCGTCTACTTCGAGAAATCGCCCAACTTCTGCACGTACAGCGGACGCCTGGGCACAGCAGGCACGGCAGGGCGCGCCTGTAACAGCTCGTCGCCCGCGCTGGACGGCTGCGAGCTGCTCTGCTGCGGCAGGGGCCACCGCACGCGCACGCAGCGCGTCACCGAGCGCTGCAACTGCACCTTCCACTGGTGCTGCCACGTCAGCTGCCGCAACTGCACGCACACGCGCGTACTGCACGAGTGTCTGTGAGGCGCTGCGCGGACTCGCCCCCAGGAACGCTCTCCTCGAGCCCTCCCCCAAACAGACTCGCTAGCACTCAAGACCCGGTTATTCGCCCACCCGAGTACCTCCAGTCACACTCCCCGCGGTTCATACGCATCCCATCTCTCCCACTTCCTCCTACCTGGGGACTCCTCAAACCACTTGCCTGGGGCGGCATGAACCCTCTTGCCATCCTGATGGACCTGCCCCGGACCTACCTCCCTCCCTCTCCGCGGGAGACCCCTTGTTGCACTGCCCCCTGCTTGGCCAGGAGGTGAGAGAAGGATGGGTCCCCTCCGCCATGGGGTCGGCTCCTGATGGTGTCATTCTGCCTGCTCCATCGCGCCAGCGACCTCTCTGCCTCTCTTCTTCCCCTTTGTCCTGCGTTTTCTCCGGGTCCTCCTAAGTCCCTTCCTATTCTCCTGCCATGGGTGCAGACCCTGAACCCACACCTGGGCATCAGGGCCTTTCTCCTCCCCACCTGTAGCTGAAGCAGGAGGTTACAGGGCAAAAGGGCAGCTGTGATGATGTGGAAATGAGGTTGGGGGAACCAGCAGAAATGCCCCCATTCTCCCAGTCTCTGTCGTGGAGCCATTGAACAGCTGTGAGCCATGCCTCCCTGGGCCACCTCCTACCCCTTCCTGTCCTGCCTCCTCATCAGTGTGTAAATAATTTGCACTGAAACGTGGATACAGAGCCACGAGTTTGGATGTTGTAAATAAAACTATTTATTGTGCTGGGTCCCAGCCTGGTTTGCAAAGACCACCTCCAACCCAACCCAATCCCTCTCCACTCTTCTCTCCTTTCTCCCTGCAGCCTTTTCTGGTCCCTCTTCTCTCCTCAGTTTCTCAAAGATGCGTTTGCCTCCTGGAATCAGTATTTCCTTCCACTGTAGCTATTAGCGGCTCCTCGCCCCCACCAGTGTAGCATCTTCCTCTGCAGAATAAAATCTCTATTTTTA\n",
      "Before reverse\n",
      "Strand  ['+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+']\n",
      "gRNA  ['GGCCGCCTCAGCCCACCAGCC', 'GCCGCCTCAGCCCACCAGCCG', 'GCTGTCCGCCGCCCGCCCCCA', 'CTGTCCGCCGCCCGCCCCCAG', 'CGCGTCCCGTCCCACCGTCGC', 'GCGTCCCGTCCCACCGTCGCG', 'GCCGCAACTGCAGCACAGAGC', 'CCGCAACTGCAGCACAGAGCG', 'AGCACAGAGCGGGCAAAGCCA', 'CAGAGCGGGCAAAGCCAGGCA', 'GGGCAAAGCCAGGCAGGCCAT', 'GGCAAAGCCAGGCAGGCCATG', 'GCAAAGCCAGGCAGGCCATGG', 'CCAGGCAGGCCATGGGGCTCT', 'CAGGCAGGCCATGGGGCTCTG', 'GGGCTCTGGGCGCTGTTGCCT', 'TCTGGGCGCTGTTGCCTGGCT', 'CTGGGCGCTGTTGCCTGGCTG', 'GGTTTCTGCTACGCTGCTGCT', 'TGCTACGCTGCTGCTGGCGCT', 'GGCCGCTCTGCCCGCAGCCCT', 'GCCCTGGCTGCCAACAGCAGT', 'CTGCCAACAGCAGTGGCCGAT', 'CCAACAGCAGTGGCCGATGGT', 'CAACAGCAGTGGCCGATGGTG', 'AACAGCAGTGGCCGATGGTGG', 'AGACTCCAAGAGTCTGCAACT', 'AGCTGTTGAGCCGCAAACAGC', 'GCGTCTGATACGCCAAAATCC', 'CGTCTGATACGCCAAAATCCG', 'GTCTGATACGCCAAAATCCGG', 'GGGATCCTGCACAGCGTGAGT', 'GGATCCTGCACAGCGTGAGTG', 'GATCCTGCACAGCGTGAGTGG', 'ATCCTGCACAGCGTGAGTGGG', 'TCCTGCACAGCGTGAGTGGGG', 'GTGCCGTGCGCGAGTGCAAGT', 'GCGAGTGCAAGTGGCAGTTCC', 'GGCAGTTCCGGAATCGCCGCT', 'TGGAACTGTCCCACTGCTCCA', 'GGAACTGTCCCACTGCTCCAG', 'GCTCCAGGGCCCCACCTCTTC', 'TTCGGCAAGATCGTCAACCGA', 'CAACCGAGGCTGTCGAGAAAC', 'ATCTTCGCTATCACCTCCGCC', 'TCTTCGCTATCACCTCCGCCG', 'CTTCGCTATCACCTCCGCCGG', 'CTCCGCCGGGGTCACCCATTC', 'CGCCGGGGTCACCCATTCGGT', 'GTGGCGCGCTCCTGCTCAGAA', 'AATCCTGCACGTGTGACTACC', 'CCTGCACGTGTGACTACCGGC', 'ACGTGTGACTACCGGCGGCGC', 'GACTACCGGCGGCGCGGCCCC', 'ACTACCGGCGGCGCGGCCCCG', 'CTACCGGCGGCGCGGCCCCGG', 'TACCGGCGGCGCGGCCCCGGG', 'GCGGCCCCGGGGGCCCCGACT', 'CCGGGGGCCCCGACTGGCACT', 'CGGGGGCCCCGACTGGCACTG', 'GGGGGCCCCGACTGGCACTGG', 'GGGGCCCCGACTGGCACTGGG', 'GGGCCCCGACTGGCACTGGGG', 'GGCCCCGACTGGCACTGGGGG', 'TGCAGCGACAACATTGACTTC', 'ATTGACTTCGGCCGCCTCTTC', 'ACTTCGGCCGCCTCTTCGGCC', 'CTTCGGCCGCCTCTTCGGCCG', 'CCTCTTCGGCCGGGAGTTCGT', 'GGCCGGGAGTTCGTGGACTCC', 'GCCGGGAGTTCGTGGACTCCG', 'CCGGGAGTTCGTGGACTCCGG', 'GTTCGTGGACTCCGGGGAGAA', 'TTCGTGGACTCCGGGGAGAAG', 'TCGTGGACTCCGGGGAGAAGG', 'TGGACTCCGGGGAGAAGGGGC', 'GGACTCCGGGGAGAAGGGGCG', 'CATGAACCTTCACAACAACGA', 'AACCTTCACAACAACGAGGCA', 'CGTATTCTCCGAGATGCGCCA', 'CGCCAGGAGTGCAAGTGCCAC', 'GCCAGGAGTGCAAGTGCCACG', 'TGCAAGTGCCACGGGATGTCC', 'CGGGATGTCCGGCTCATGCAC', 'CATGCACGGTGCGCACGTGCT', 'CGGTGCGCACGTGCTGGATGC', 'GCTGCCCACGCTGCGCGCCGT', 'CTGCCCACGCTGCGCGCCGTG', 'GTGCTGCGCGACCGCTTCGAC', 'GGCGCCTCGCGCGTCCTGTAC', 'CGCGTCCTGTACGGCAACCGC', 'GCGGCAGCAACCGCGCTTCGC', 'CGGCAGCAACCGCGCTTCGCG', 'CAGCAACCGCGCTTCGCGGGC', 'GCGGGCGGAGCTGCTGCGCCT', 'GGAGCTGCTGCGCCTGGAGCC', 'GCGCCTGGAGCCGGAAGACCC', 'CCCAACTTCTGCACGTACAGC', 'CTGCACGTACAGCGGACGCCT', 'TGCACGTACAGCGGACGCCTG', 'AGCGGACGCCTGGGCACAGCA', 'ACGCCTGGGCACAGCAGGCAC', 'CTGGGCACAGCAGGCACGGCA', 'TGGGCACAGCAGGCACGGCAG', 'TAACAGCTCGTCGCCCGCGCT', 'AGCTCGTCGCCCGCGCTGGAC', 'GGCTGCGAGCTGCTCTGCTGC', 'GCGAGCTGCTCTGCTGCGGCA', 'CGAGCTGCTCTGCTGCGGCAG', 'GAGCTGCTCTGCTGCGGCAGG', 'GCTGCAACTGCACCTTCCACT', 'GTACTGCACGAGTGTCTGTGA', 'AGTGTCTGTGAGGCGCTGCGC', 'CGCTGCGCGGACTCGCCCCCA', 'ACTCGCTAGCACTCAAGACCC', 'ACCTCCAGTCACACTCCCCGC', 'CTCTCCCACTTCCTCCTACCT', 'TCTCCCACTTCCTCCTACCTG', 'CTCCCACTTCCTCCTACCTGG', 'GACTCCTCAAACCACTTGCCT', 'ACTCCTCAAACCACTTGCCTG', 'CTCCTCAAACCACTTGCCTGG', 'CTCAAACCACTTGCCTGGGGC', 'GAACCCTCTTGCCATCCTGAT', 'CCATCCTGATGGACCTGCCCC', 'CCTACCTCCCTCCCTCTCCGC', 'CTACCTCCCTCCCTCTCCGCG', 'TTGTTGCACTGCCCCCTGCTT', 'GCACTGCCCCCTGCTTGGCCA', 'CTGCCCCCTGCTTGGCCAGGA', 'CTTGGCCAGGAGGTGAGAGAA', 'GCCAGGAGGTGAGAGAAGGAT', 'CCAGGAGGTGAGAGAAGGATG', 'AGGATGGGTCCCCTCCGCCAT', 'GGATGGGTCCCCTCCGCCATG', 'GATGGGTCCCCTCCGCCATGG', 'GGTCCCCTCCGCCATGGGGTC', 'GCCATGGGGTCGGCTCCTGAT', 'CCTTTGTCCTGCGTTTTCTCC', 'CTTTGTCCTGCGTTTTCTCCG', 'CCCTTCCTATTCTCCTGCCAT', 'CCTTCCTATTCTCCTGCCATG', 'GCAGACCCTGAACCCACACCT', 'CAGACCCTGAACCCACACCTG', 'TGAACCCACACCTGGGCATCA', 'GAACCCACACCTGGGCATCAG', 'TCCCCACCTGTAGCTGAAGCA', 'CCACCTGTAGCTGAAGCAGGA', 'TAGCTGAAGCAGGAGGTTACA', 'AGCTGAAGCAGGAGGTTACAG', 'GCAGGAGGTTACAGGGCAAAA', 'CAGGAGGTTACAGGGCAAAAG', 'AAAGGGCAGCTGTGATGATGT', 'GCTGTGATGATGTGGAAATGA', 'TGATGATGTGGAAATGAGGTT', 'GATGATGTGGAAATGAGGTTG', 'ATGATGTGGAAATGAGGTTGG', 'TGATGTGGAAATGAGGTTGGG', 'CATTCTCCCAGTCTCTGTCGT', 'AGCTGTGAGCCATGCCTCCCT', 'GCTGTGAGCCATGCCTCCCTG', 'AAATAATTTGCACTGAAACGT', 'TGGATACAGAGCCACGAGTTT', 'AATAAAACTATTTATTGTGCT', 'ATAAAACTATTTATTGTGCTG', 'TATTGTGCTGGGTCCCAGCCT', 'TTTCTCCCTGCAGCCTTTTCT', 'TCAAAGATGCGTTTGCCTCCT', 'CCTTCCACTGTAGCTATTAGC']\n",
      "Cut_Pos  [34, 35, 70, 71, 137, 138, 175, 176, 186, 190, 196, 197, 198, 204, 205, 218, 222, 223, 244, 250, 271, 287, 294, 297, 298, 299, 358, 399, 421, 422, 423, 443, 444, 445, 446, 447, 477, 486, 498, 518, 519, 533, 551, 565, 593, 594, 595, 607, 610, 629, 660, 663, 668, 674, 675, 676, 677, 687, 693, 694, 695, 696, 697, 698, 722, 734, 738, 739, 748, 755, 756, 757, 763, 764, 765, 768, 769, 805, 809, 841, 857, 858, 866, 877, 891, 897, 919, 920, 947, 968, 977, 996, 997, 1000, 1015, 1021, 1030, 1100, 1108, 1109, 1118, 1123, 1127, 1128, 1159, 1163, 1184, 1188, 1189, 1190, 1245, 1307, 1317, 1330, 1383, 1424, 1463, 1464, 1465, 1487, 1488, 1489, 1492, 1518, 1529, 1553, 1554, 1584, 1589, 1592, 1602, 1606, 1607, 1622, 1623, 1624, 1628, 1638, 1713, 1714, 1748, 1749, 1773, 1774, 1781, 1782, 1814, 1817, 1824, 1825, 1832, 1833, 1850, 1858, 1862, 1863, 1864, 1865, 1906, 1940, 1941, 2006, 2026, 2057, 2058, 2069, 2143, 2188, 2222]\n",
      "PAM  ['CGG', 'GGG', 'AGG', 'GGG', 'CGG', 'GGG', 'CGG', 'GGG', 'AGG', 'AGG', 'TGG', 'GGG', 'GGG', 'TGG', 'GGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'TGG', 'TGG', 'TGG', 'GGG', 'GGG', 'TGG', 'CGG', 'CGG', 'GGG', 'GGG', 'TGG', 'GGG', 'GGG', 'GGG', 'GGG', 'TGG', 'CGG', 'TGG', 'AGG', 'GGG', 'CGG', 'AGG', 'CGG', 'CGG', 'GGG', 'GGG', 'CGG', 'TGG', 'AGG', 'CGG', 'CGG', 'CGG', 'CGG', 'GGG', 'GGG', 'GGG', 'TGG', 'TGG', 'GGG', 'GGG', 'GGG', 'GGG', 'GGG', 'CGG', 'CGG', 'CGG', 'GGG', 'TGG', 'CGG', 'GGG', 'GGG', 'AGG', 'GGG', 'GGG', 'CGG', 'GGG', 'AGG', 'AGG', 'AGG', 'CGG', 'GGG', 'CGG', 'CGG', 'TGG', 'CGG', 'TGG', 'GGG', 'CGG', 'CGG', 'CGG', 'CGG', 'GGG', 'CGG', 'TGG', 'CGG', 'CGG', 'CGG', 'TGG', 'GGG', 'AGG', 'CGG', 'AGG', 'GGG', 'TGG', 'CGG', 'CGG', 'AGG', 'GGG', 'GGG', 'TGG', 'AGG', 'CGG', 'AGG', 'CGG', 'CGG', 'TGG', 'GGG', 'GGG', 'TGG', 'GGG', 'GGG', 'CGG', 'TGG', 'CGG', 'CGG', 'GGG', 'TGG', 'AGG', 'AGG', 'AGG', 'TGG', 'GGG', 'TGG', 'GGG', 'GGG', 'CGG', 'TGG', 'CGG', 'GGG', 'TGG', 'GGG', 'TGG', 'GGG', 'AGG', 'GGG', 'AGG', 'AGG', 'AGG', 'GGG', 'AGG', 'GGG', 'TGG', 'AGG', 'TGG', 'GGG', 'GGG', 'GGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'CGG']\n",
      "\n",
      "\n",
      "After reverse\n",
      "Strand  ['+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']\n",
      "gRNA  ['GGCCGCCTCAGCCCACCAGCC', 'GCCGCCTCAGCCCACCAGCCG', 'GCTGTCCGCCGCCCGCCCCCA', 'CTGTCCGCCGCCCGCCCCCAG', 'CGCGTCCCGTCCCACCGTCGC', 'GCGTCCCGTCCCACCGTCGCG', 'GCCGCAACTGCAGCACAGAGC', 'CCGCAACTGCAGCACAGAGCG', 'AGCACAGAGCGGGCAAAGCCA', 'CAGAGCGGGCAAAGCCAGGCA', 'GGGCAAAGCCAGGCAGGCCAT', 'GGCAAAGCCAGGCAGGCCATG', 'GCAAAGCCAGGCAGGCCATGG', 'CCAGGCAGGCCATGGGGCTCT', 'CAGGCAGGCCATGGGGCTCTG', 'GGGCTCTGGGCGCTGTTGCCT', 'TCTGGGCGCTGTTGCCTGGCT', 'CTGGGCGCTGTTGCCTGGCTG', 'GGTTTCTGCTACGCTGCTGCT', 'TGCTACGCTGCTGCTGGCGCT', 'GGCCGCTCTGCCCGCAGCCCT', 'GCCCTGGCTGCCAACAGCAGT', 'CTGCCAACAGCAGTGGCCGAT', 'CCAACAGCAGTGGCCGATGGT', 'CAACAGCAGTGGCCGATGGTG', 'AACAGCAGTGGCCGATGGTGG', 'AGACTCCAAGAGTCTGCAACT', 'AGCTGTTGAGCCGCAAACAGC', 'GCGTCTGATACGCCAAAATCC', 'CGTCTGATACGCCAAAATCCG', 'GTCTGATACGCCAAAATCCGG', 'GGGATCCTGCACAGCGTGAGT', 'GGATCCTGCACAGCGTGAGTG', 'GATCCTGCACAGCGTGAGTGG', 'ATCCTGCACAGCGTGAGTGGG', 'TCCTGCACAGCGTGAGTGGGG', 'GTGCCGTGCGCGAGTGCAAGT', 'GCGAGTGCAAGTGGCAGTTCC', 'GGCAGTTCCGGAATCGCCGCT', 'TGGAACTGTCCCACTGCTCCA', 'GGAACTGTCCCACTGCTCCAG', 'GCTCCAGGGCCCCACCTCTTC', 'TTCGGCAAGATCGTCAACCGA', 'CAACCGAGGCTGTCGAGAAAC', 'ATCTTCGCTATCACCTCCGCC', 'TCTTCGCTATCACCTCCGCCG', 'CTTCGCTATCACCTCCGCCGG', 'CTCCGCCGGGGTCACCCATTC', 'CGCCGGGGTCACCCATTCGGT', 'GTGGCGCGCTCCTGCTCAGAA', 'AATCCTGCACGTGTGACTACC', 'CCTGCACGTGTGACTACCGGC', 'ACGTGTGACTACCGGCGGCGC', 'GACTACCGGCGGCGCGGCCCC', 'ACTACCGGCGGCGCGGCCCCG', 'CTACCGGCGGCGCGGCCCCGG', 'TACCGGCGGCGCGGCCCCGGG', 'GCGGCCCCGGGGGCCCCGACT', 'CCGGGGGCCCCGACTGGCACT', 'CGGGGGCCCCGACTGGCACTG', 'GGGGGCCCCGACTGGCACTGG', 'GGGGCCCCGACTGGCACTGGG', 'GGGCCCCGACTGGCACTGGGG', 'GGCCCCGACTGGCACTGGGGG', 'TGCAGCGACAACATTGACTTC', 'ATTGACTTCGGCCGCCTCTTC', 'ACTTCGGCCGCCTCTTCGGCC', 'CTTCGGCCGCCTCTTCGGCCG', 'CCTCTTCGGCCGGGAGTTCGT', 'GGCCGGGAGTTCGTGGACTCC', 'GCCGGGAGTTCGTGGACTCCG', 'CCGGGAGTTCGTGGACTCCGG', 'GTTCGTGGACTCCGGGGAGAA', 'TTCGTGGACTCCGGGGAGAAG', 'TCGTGGACTCCGGGGAGAAGG', 'TGGACTCCGGGGAGAAGGGGC', 'GGACTCCGGGGAGAAGGGGCG', 'CATGAACCTTCACAACAACGA', 'AACCTTCACAACAACGAGGCA', 'CGTATTCTCCGAGATGCGCCA', 'CGCCAGGAGTGCAAGTGCCAC', 'GCCAGGAGTGCAAGTGCCACG', 'TGCAAGTGCCACGGGATGTCC', 'CGGGATGTCCGGCTCATGCAC', 'CATGCACGGTGCGCACGTGCT', 'CGGTGCGCACGTGCTGGATGC', 'GCTGCCCACGCTGCGCGCCGT', 'CTGCCCACGCTGCGCGCCGTG', 'GTGCTGCGCGACCGCTTCGAC', 'GGCGCCTCGCGCGTCCTGTAC', 'CGCGTCCTGTACGGCAACCGC', 'GCGGCAGCAACCGCGCTTCGC', 'CGGCAGCAACCGCGCTTCGCG', 'CAGCAACCGCGCTTCGCGGGC', 'GCGGGCGGAGCTGCTGCGCCT', 'GGAGCTGCTGCGCCTGGAGCC', 'GCGCCTGGAGCCGGAAGACCC', 'CCCAACTTCTGCACGTACAGC', 'CTGCACGTACAGCGGACGCCT', 'TGCACGTACAGCGGACGCCTG', 'AGCGGACGCCTGGGCACAGCA', 'ACGCCTGGGCACAGCAGGCAC', 'CTGGGCACAGCAGGCACGGCA', 'TGGGCACAGCAGGCACGGCAG', 'TAACAGCTCGTCGCCCGCGCT', 'AGCTCGTCGCCCGCGCTGGAC', 'GGCTGCGAGCTGCTCTGCTGC', 'GCGAGCTGCTCTGCTGCGGCA', 'CGAGCTGCTCTGCTGCGGCAG', 'GAGCTGCTCTGCTGCGGCAGG', 'GCTGCAACTGCACCTTCCACT', 'GTACTGCACGAGTGTCTGTGA', 'AGTGTCTGTGAGGCGCTGCGC', 'CGCTGCGCGGACTCGCCCCCA', 'ACTCGCTAGCACTCAAGACCC', 'ACCTCCAGTCACACTCCCCGC', 'CTCTCCCACTTCCTCCTACCT', 'TCTCCCACTTCCTCCTACCTG', 'CTCCCACTTCCTCCTACCTGG', 'GACTCCTCAAACCACTTGCCT', 'ACTCCTCAAACCACTTGCCTG', 'CTCCTCAAACCACTTGCCTGG', 'CTCAAACCACTTGCCTGGGGC', 'GAACCCTCTTGCCATCCTGAT', 'CCATCCTGATGGACCTGCCCC', 'CCTACCTCCCTCCCTCTCCGC', 'CTACCTCCCTCCCTCTCCGCG', 'TTGTTGCACTGCCCCCTGCTT', 'GCACTGCCCCCTGCTTGGCCA', 'CTGCCCCCTGCTTGGCCAGGA', 'CTTGGCCAGGAGGTGAGAGAA', 'GCCAGGAGGTGAGAGAAGGAT', 'CCAGGAGGTGAGAGAAGGATG', 'AGGATGGGTCCCCTCCGCCAT', 'GGATGGGTCCCCTCCGCCATG', 'GATGGGTCCCCTCCGCCATGG', 'GGTCCCCTCCGCCATGGGGTC', 'GCCATGGGGTCGGCTCCTGAT', 'CCTTTGTCCTGCGTTTTCTCC', 'CTTTGTCCTGCGTTTTCTCCG', 'CCCTTCCTATTCTCCTGCCAT', 'CCTTCCTATTCTCCTGCCATG', 'GCAGACCCTGAACCCACACCT', 'CAGACCCTGAACCCACACCTG', 'TGAACCCACACCTGGGCATCA', 'GAACCCACACCTGGGCATCAG', 'TCCCCACCTGTAGCTGAAGCA', 'CCACCTGTAGCTGAAGCAGGA', 'TAGCTGAAGCAGGAGGTTACA', 'AGCTGAAGCAGGAGGTTACAG', 'GCAGGAGGTTACAGGGCAAAA', 'CAGGAGGTTACAGGGCAAAAG', 'AAAGGGCAGCTGTGATGATGT', 'GCTGTGATGATGTGGAAATGA', 'TGATGATGTGGAAATGAGGTT', 'GATGATGTGGAAATGAGGTTG', 'ATGATGTGGAAATGAGGTTGG', 'TGATGTGGAAATGAGGTTGGG', 'CATTCTCCCAGTCTCTGTCGT', 'AGCTGTGAGCCATGCCTCCCT', 'GCTGTGAGCCATGCCTCCCTG', 'AAATAATTTGCACTGAAACGT', 'TGGATACAGAGCCACGAGTTT', 'AATAAAACTATTTATTGTGCT', 'ATAAAACTATTTATTGTGCTG', 'TATTGTGCTGGGTCCCAGCCT', 'TTTCTCCCTGCAGCCTTTTCT', 'TCAAAGATGCGTTTGCCTCCT', 'CCTTCCACTGTAGCTATTAGC', 'ATAGAGATTTTATTCTGCAGA', 'TGCAGAGGAAGATGCTACACT', 'AGAGGAAGATGCTACACTGGT', 'GAGGAAGATGCTACACTGGTG', 'AGGAAGATGCTACACTGGTGG', 'GGAAGATGCTACACTGGTGGG', 'ATGCTACACTGGTGGGGGCGA', 'GGAGCCGCTAATAGCTACAGT', 'CCGCTAATAGCTACAGTGGAA', 'TGGAAGGAAATACTGATTCCA', 'AAGGAAATACTGATTCCAGGA', 'AACGCATCTTTGAGAAACTGA', 'TGAGAAACTGAGGAGAGAAGA', 'GAGAAACTGAGGAGAGAAGAG', 'GAGAGAAGAGGGACCAGAAAA', 'GAGGGACCAGAAAAGGCTGCA', 'AGGGACCAGAAAAGGCTGCAG', 'AGAAAAGGCTGCAGGGAGAAA', 'AGGGAGAAAGGAGAGAAGAGT', 'GAAAGGAGAGAAGAGTGGAGA', 'AAAGGAGAGAAGAGTGGAGAG', 'AGAGAAGAGTGGAGAGGGATT', 'GAGAAGAGTGGAGAGGGATTG', 'AGAGTGGAGAGGGATTGGGTT', 'GAGTGGAGAGGGATTGGGTTG', 'GGAGAGGGATTGGGTTGGGTT', 'GAGGGATTGGGTTGGGTTGGA', 'GGATTGGGTTGGGTTGGAGGT', 'GGAGGTGGTCTTTGCAAACCA', 'GTGGTCTTTGCAAACCAGGCT', 'TGGTCTTTGCAAACCAGGCTG', 'ATTTACAACATCCAAACTCGT', 'AAATTATTTACACACTGATGA', 'TTATTTACACACTGATGAGGA', 'TTACACACTGATGAGGAGGCA', 'CACTGATGAGGAGGCAGGACA', 'GATGAGGAGGCAGGACAGGAA', 'ATGAGGAGGCAGGACAGGAAG', 'TGAGGAGGCAGGACAGGAAGG', 'GAGGCAGGACAGGAAGGGGTA', 'GCAGGACAGGAAGGGGTAGGA', 'GGACAGGAAGGGGTAGGAGGT', 'GAAGGGGTAGGAGGTGGCCCA', 'AAGGGGTAGGAGGTGGCCCAG', 'GGGTAGGAGGTGGCCCAGGGA', 'GGAGGTGGCCCAGGGAGGCAT', 'CATGGCTCACAGCTGTTCAAT', 'AATGGCTCCACGACAGAGACT', 'ATGGCTCCACGACAGAGACTG', 'CACGACAGAGACTGGGAGAAT', 'ACGACAGAGACTGGGAGAATG', 'CGACAGAGACTGGGAGAATGG', 'GACAGAGACTGGGAGAATGGG', 'GAGAATGGGGGCATTTCTGCT', 'TAACCTCCTGCTTCAGCTACA', 'CCTCCTGCTTCAGCTACAGGT', 'CTCCTGCTTCAGCTACAGGTG', 'TCCTGCTTCAGCTACAGGTGG', 'TGCTTCAGCTACAGGTGGGGA', 'GCTACAGGTGGGGAGGAGAAA', 'GGAGAAAGGCCCTGATGCCCA', 'AAGGCCCTGATGCCCAGGTGT', 'AGGCCCTGATGCCCAGGTGTG', 'TGATGCCCAGGTGTGGGTTCA', 'GATGCCCAGGTGTGGGTTCAG', 'GGGTTCAGGGTCTGCACCCAT', 'TCAGGGTCTGCACCCATGGCA', 'TGCACCCATGGCAGGAGAATA', 'CCCATGGCAGGAGAATAGGAA', 'CCATGGCAGGAGAATAGGAAG', 'AGGAGAATAGGAAGGGACTTA', 'AGAATAGGAAGGGACTTAGGA', 'GGAAGGGACTTAGGAGGACCC', 'GGAGGACCCGGAGAAAACGCA', 'CCGGAGAAAACGCAGGACAAA', 'CGGAGAAAACGCAGGACAAAG', 'GGAGAAAACGCAGGACAAAGG', 'AGGACAAAGGGGAAGAAGAGA', 'GGGGAAGAAGAGAGGCAGAGA', 'AAGAGAGGCAGAGAGGTCGCT', 'CAGAGAGGTCGCTGGCGCGAT', 'GGTCGCTGGCGCGATGGAGCA', 'GCAGGCAGAATGACACCATCA', 'ACCATCAGGAGCCGACCCCAT', 'ATCAGGAGCCGACCCCATGGC', 'AGGAGCCGACCCCATGGCGGA', 'GGAGCCGACCCCATGGCGGAG', 'GAGCCGACCCCATGGCGGAGG', 'CCCATCCTTCTCTCACCTCCT', 'CTCTCACCTCCTGGCCAAGCA', 'TCTCACCTCCTGGCCAAGCAG', 'CTCACCTCCTGGCCAAGCAGG', 'TCACCTCCTGGCCAAGCAGGG', 'AAGCAGGGGGCAGTGCAACAA', 'AGCAGGGGGCAGTGCAACAAG', 'GCAGGGGGCAGTGCAACAAGG', 'GTGCAACAAGGGGTCTCCCGC', 'ACAAGGGGTCTCCCGCGGAGA', 'CAAGGGGTCTCCCGCGGAGAG', 'GGGGTCTCCCGCGGAGAGGGA', 'GGGTCTCCCGCGGAGAGGGAG', 'TCTCCCGCGGAGAGGGAGGGA', 'CCGCGGAGAGGGAGGGAGGTA', 'GAGAGGGAGGGAGGTAGGTCC', 'AGAGGGAGGGAGGTAGGTCCG', 'GAGGGAGGGAGGTAGGTCCGG', 'GAGGGAGGTAGGTCCGGGGCA', 'AGGTCCGGGGCAGGTCCATCA', 'CCGGGGCAGGTCCATCAGGAT', 'AGGTCCATCAGGATGGCAAGA', 'GGTCCATCAGGATGGCAAGAG', 'AAGAGGGTTCATGCCGCCCCA', 'TTCATGCCGCCCCAGGCAAGT', 'CGCCCCAGGCAAGTGGTTTGA', 'AAGTGGTTTGAGGAGTCCCCA', 'GGTTTGAGGAGTCCCCAGGTA', 'TTGAGGAGTCCCCAGGTAGGA', 'AGTCCCCAGGTAGGAGGAAGT', 'GTCCCCAGGTAGGAGGAAGTG', 'GTAGGAGGAAGTGGGAGAGAT', 'TAGGAGGAAGTGGGAGAGATG', 'GATGGGATGCGTATGAACCGC', 'ATGGGATGCGTATGAACCGCG', 'TGGGATGCGTATGAACCGCGG', 'TGAACCGCGGGGAGTGTGACT', 'ACCGCGGGGAGTGTGACTGGA', 'GGAGTGTGACTGGAGGTACTC', 'GAGTGTGACTGGAGGTACTCG', 'TGTGACTGGAGGTACTCGGGT', 'GTGACTGGAGGTACTCGGGTG', 'TACTCGGGTGGGCGAATAACC', 'ACTCGGGTGGGCGAATAACCG', 'TGAGTGCTAGCGAGTCTGTTT', 'GAGTGCTAGCGAGTCTGTTTG', 'AGTGCTAGCGAGTCTGTTTGG', 'GTGCTAGCGAGTCTGTTTGGG', 'CTAGCGAGTCTGTTTGGGGGA', 'TAGCGAGTCTGTTTGGGGGAG', 'TCTGTTTGGGGGAGGGCTCGA', 'GGGCTCGAGGAGAGCGTTCCT', 'GGCTCGAGGAGAGCGTTCCTG', 'GCTCGAGGAGAGCGTTCCTGG', 'CTCGAGGAGAGCGTTCCTGGG', 'CGCGCGTGTGCGTGCAGTTGC', 'TGCAGTTGCGGCAGCTGACGT', 'AGCTGACGTGGCAGCACCAGT', 'GACGTGGCAGCACCAGTGGAA', 'GAAGGTGCAGTTGCAGCGCTC', 'TGACGCGCTGCGTGCGCGTGC', 'CGCGCTGCGTGCGCGTGCGGT', 'CAGCTCGCAGCCGTCCAGCGC', 'AGCTCGCAGCCGTCCAGCGCG', 'CGCGGGCGACGAGCTGTTACA', 'CTGCCGTGCCTGCTGTGCCCA', 'TCCGCTGTACGTGCAGAAGTT', 'CCGCTGTACGTGCAGAAGTTG', 'GCGATTTCTCGAAGTAGACGA', 'TCTCGAAGTAGACGAGGTCGT', 'CTCGAAGTAGACGAGGTCGTG', 'TCGAAGTAGACGAGGTCGTGG', 'CGAAGTAGACGAGGTCGTGGG', 'GAAGTAGACGAGGTCGTGGGG', 'GTAGACGAGGTCGTGGGGGGA', 'TAGACGAGGTCGTGGGGGGAG', 'ACGAGGTCGTGGGGGGAGGGC', 'CGTGGGGGGAGGGCGGTTTGT', 'GTGGGGGGAGGGCGGTTTGTG', 'GGGGAGGGCGGTTTGTGGGCC', 'GGGAGGGCGGTTTGTGGGCCG', 'GGTTTGTGGGCCGGGTCTTCC', 'GGGCCGGGTCTTCCGGCTCCA', 'GCAGCTCCGCCCGCGAAGCGC', 'GCGAAGCGCGGTTGCTGCCGC', 'TGCTGCCGCGGTTGCCGTACA', 'GTTGCCGTACAGGACGCGCGA', 'CGCGCGAGGCGCCGTCGAAGC', 'GTCGCGCAGCACATCGCCCAC', 'ATCGCCCACGGCGCGCAGCGT', 'TCGCCCACGGCGCGCAGCGTG', 'CGTGCGCACCGTGCATGAGCC', 'TGCATGAGCCGGACATCCCGT', 'TCCCGTGGCACTTGCACTCCT', 'CTTGCACTCCTGGCGCATCTC', 'CTGGCGCATCTCGGAGAATAC', 'TCTCGGAGAATACGGTCGTAC', 'GGCCTGCCTCGTTGTTGTGAA', 'CGTTGTTGTGAAGGTTCATGA', 'GAAGGTTCATGAGGAAGCGCA', 'CAGGTCCCGCCCCTTCTCCCC', 'CCCCGGAGTCCACGAACTCCC', 'CCACGAACTCCCGGCCGAAGA', 'CGAACTCCCGGCCGAAGAGGC', 'GCAGCCCCCCCAGTGCCAGTC', 'CAGCCCCCCCAGTGCCAGTCG', 'AGCCCCCCCAGTGCCAGTCGG', 'CCAGTGCCAGTCGGGGCCCCC', 'CAGTGCCAGTCGGGGCCCCCG', 'AGTGCCAGTCGGGGCCCCCGG', 'GGCCCCCGGGGCCGCGCCGCC', 'CCGCCGGTAGTCACACGTGCA', 'GTCACACGTGCAGGATTCGAT', 'TTCGATGGAACCTTCTGAGCA', 'AGCAGGAGCGCGCCACCGAAT', 'GCAGGAGCGCGCCACCGAATG', 'CGCCACCGAATGGGTGACCCC', 'CACCGAATGGGTGACCCCGGC', 'CGAATGGGTGACCCCGGCGGA', 'ACGCCGTTTCTCGACAGCCTC', 'GGTTGACGATCTTGCCGAAGA', 'TGACGATCTTGCCGAAGAGGT', 'GACGATCTTGCCGAAGAGGTG', 'ACGATCTTGCCGAAGAGGTGG', 'TTGCCGAAGAGGTGGGGCCCT', 'GAGGTGGGGCCCTGGAGCAGT', 'AGGTGGGGCCCTGGAGCAGTG', 'GAGCAGTGGGACAGTTCCAGC', 'GACAGTTCCAGCGGCGATTCC', 'CTGCCACTTGCACTCGCGCAC', 'GCCCCCCACTCACGCTGTGCA', 'CTCACGCTGTGCAGGATCCCC', 'TGTGCAGGATCCCCGGATTTT', 'GTATCAGACGCCGCTGTTTGC', 'GCGGCTCAACAGCTGCAGACT', 'CGGCTCAACAGCTGCAGACTG', 'GAGTACCAGTTGCAGACTCTT', 'GACTCTTGGAGTCTGTAAGCA', 'GGAGTCTGTAAGCAGGTTCGT', 'GTCTGTAAGCAGGTTCGTGGA', 'TGTAAGCAGGTTCGTGGAGGA', 'CGTTCACAATACCCCACCATC', 'CCACCATCGGCCACTGCTGTT', 'GGCCACTGCTGTTGGCAGCCA', 'GCCACTGCTGTTGGCAGCCAG', 'GCTGTTGGCAGCCAGGGCTGC', 'CTGTTGGCAGCCAGGGCTGCG', 'AGCCAGGGCTGCGGGCAGAGC', 'AGCGTAGCAGAAACCCAGCCA', 'CAACAGCGCCCAGAGCCCCAT', 'CCAGAGCCCCATGGCCTGCCT', 'CCCGCTCTGTGCTGCAGTTGC', 'TGCTGCAGTTGCGGCGACTTT', 'ACTTTGGTTGTTGCCCGCGAC', 'TTGGTTGTTGCCCGCGACGGT', 'TGGTTGTTGCCCGCGACGGTG', 'TGTTGCCCGCGACGGTGGGAC', 'GTTGCCCGCGACGGTGGGACG', 'CGCGACGGTGGGACGGGACGC', 'GACGGTGGGACGGGACGCGGC', 'GGTGGGACGGGACGCGGCGGT', 'GGGACGGGACGCGGCGGTGGC', 'GGACGCGGCGGTGGCGGCAGT', 'AGTGGCGAGAGTTCGCAGTCT', 'CAGTCTGGCTTTAACAACCCT', 'AGTCTGGCTTTAACAACCCTG', 'GTCTGGCTTTAACAACCCTGG', 'TCTGGCTTTAACAACCCTGGG', 'GGCTTTAACAACCCTGGGGGC', 'GCTTTAACAACCCTGGGGGCG', 'TTAACAACCCTGGGGGCGGGC', 'ACAACCCTGGGGGCGGGCGGC', 'GGGGCGGGCGGCGGACAGCAT', 'GCGGCGGACAGCATGGCTCGC', 'GACAGCATGGCTCGCGGTCCC', 'GCATGGCTCGCGGTCCCGGCT', 'TGGCTCGCGGTCCCGGCTGGT', 'GGCTCGCGGTCCCGGCTGGTG', 'CGGTCCCGGCTGGTGGGCTGA', 'TCCCGGCTGGTGGGCTGAGGC', 'CTGGTGGGCTGAGGCGGCCAC', 'GTGGGCTGAGGCGGCCACGGC', 'TGGGCTGAGGCGGCCACGGCG', 'GCTGAGGCGGCCACGGCGGGC']\n",
      "Cut_Pos  [34, 35, 70, 71, 137, 138, 175, 176, 186, 190, 196, 197, 198, 204, 205, 218, 222, 223, 244, 250, 271, 287, 294, 297, 298, 299, 358, 399, 421, 422, 423, 443, 444, 445, 446, 447, 477, 486, 498, 518, 519, 533, 551, 565, 593, 594, 595, 607, 610, 629, 660, 663, 668, 674, 675, 676, 677, 687, 693, 694, 695, 696, 697, 698, 722, 734, 738, 739, 748, 755, 756, 757, 763, 764, 765, 768, 769, 805, 809, 841, 857, 858, 866, 877, 891, 897, 919, 920, 947, 968, 977, 996, 997, 1000, 1015, 1021, 1030, 1100, 1108, 1109, 1118, 1123, 1127, 1128, 1159, 1163, 1184, 1188, 1189, 1190, 1245, 1307, 1317, 1330, 1383, 1424, 1463, 1464, 1465, 1487, 1488, 1489, 1492, 1518, 1529, 1553, 1554, 1584, 1589, 1592, 1602, 1606, 1607, 1622, 1623, 1624, 1628, 1638, 1713, 1714, 1748, 1749, 1773, 1774, 1781, 1782, 1814, 1817, 1824, 1825, 1832, 1833, 1850, 1858, 1862, 1863, 1864, 1865, 1906, 1940, 1941, 2006, 2026, 2057, 2058, 2069, 2143, 2188, 2222, 22, 37, 40, 41, 42, 43, 48, 69, 73, 89, 92, 117, 127, 128, 139, 146, 147, 154, 166, 171, 172, 177, 178, 182, 183, 187, 190, 193, 208, 212, 213, 258, 303, 306, 310, 315, 319, 320, 321, 325, 328, 331, 337, 338, 341, 346, 364, 382, 383, 390, 391, 392, 393, 405, 475, 478, 479, 480, 483, 490, 504, 509, 510, 516, 517, 530, 534, 542, 546, 547, 554, 557, 563, 575, 582, 583, 584, 595, 603, 610, 618, 624, 642, 656, 659, 662, 663, 664, 688, 697, 698, 699, 700, 713, 714, 715, 725, 730, 731, 734, 735, 738, 742, 747, 748, 749, 753, 762, 766, 773, 774, 790, 797, 804, 814, 818, 821, 827, 828, 836, 837, 854, 855, 856, 867, 870, 877, 878, 881, 882, 893, 894, 920, 921, 922, 923, 926, 927, 934, 947, 948, 949, 950, 1010, 1022, 1034, 1038, 1056, 1079, 1082, 1122, 1123, 1140, 1169, 1194, 1195, 1217, 1223, 1224, 1225, 1226, 1227, 1230, 1231, 1234, 1241, 1242, 1246, 1247, 1255, 1262, 1289, 1301, 1313, 1323, 1337, 1359, 1371, 1372, 1410, 1421, 1436, 1446, 1455, 1463, 1484, 1493, 1502, 1521, 1538, 1547, 1550, 1593, 1594, 1595, 1602, 1603, 1604, 1616, 1632, 1641, 1656, 1673, 1674, 1683, 1686, 1689, 1727, 1748, 1751, 1752, 1753, 1759, 1767, 1768, 1781, 1790, 1815, 1847, 1855, 1862, 1886, 1905, 1906, 1932, 1946, 1953, 1956, 1959, 1985, 1998, 2006, 2007, 2013, 2014, 2022, 2059, 2082, 2091, 2119, 2128, 2144, 2147, 2148, 2152, 2153, 2159, 2162, 2165, 2168, 2174, 2192, 2207, 2208, 2209, 2210, 2213, 2214, 2217, 2220, 2229, 2236, 2242, 2246, 2249, 2250, 2256, 2259, 2265, 2268, 2269, 2272]\n",
      "PAM  ['CGG', 'GGG', 'AGG', 'GGG', 'CGG', 'GGG', 'CGG', 'GGG', 'AGG', 'AGG', 'TGG', 'GGG', 'GGG', 'TGG', 'GGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'TGG', 'TGG', 'TGG', 'GGG', 'GGG', 'TGG', 'CGG', 'CGG', 'GGG', 'GGG', 'TGG', 'GGG', 'GGG', 'GGG', 'GGG', 'TGG', 'CGG', 'TGG', 'AGG', 'GGG', 'CGG', 'AGG', 'CGG', 'CGG', 'GGG', 'GGG', 'CGG', 'TGG', 'AGG', 'CGG', 'CGG', 'CGG', 'CGG', 'GGG', 'GGG', 'GGG', 'TGG', 'TGG', 'GGG', 'GGG', 'GGG', 'GGG', 'GGG', 'CGG', 'CGG', 'CGG', 'GGG', 'TGG', 'CGG', 'GGG', 'GGG', 'AGG', 'GGG', 'GGG', 'CGG', 'GGG', 'AGG', 'AGG', 'AGG', 'CGG', 'GGG', 'CGG', 'CGG', 'TGG', 'CGG', 'TGG', 'GGG', 'CGG', 'CGG', 'CGG', 'CGG', 'GGG', 'CGG', 'TGG', 'CGG', 'CGG', 'CGG', 'TGG', 'GGG', 'AGG', 'CGG', 'AGG', 'GGG', 'TGG', 'CGG', 'CGG', 'AGG', 'GGG', 'GGG', 'TGG', 'AGG', 'CGG', 'AGG', 'CGG', 'CGG', 'TGG', 'GGG', 'GGG', 'TGG', 'GGG', 'GGG', 'CGG', 'TGG', 'CGG', 'CGG', 'GGG', 'TGG', 'AGG', 'AGG', 'AGG', 'TGG', 'GGG', 'TGG', 'GGG', 'GGG', 'CGG', 'TGG', 'CGG', 'GGG', 'TGG', 'GGG', 'TGG', 'GGG', 'AGG', 'GGG', 'AGG', 'AGG', 'AGG', 'GGG', 'AGG', 'GGG', 'TGG', 'AGG', 'TGG', 'GGG', 'GGG', 'GGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'GGG', 'TGG', 'TGG', 'TGG', 'CGG', 'AGG', 'TGG', 'TGG', 'GGG', 'GGG', 'GGG', 'AGG', 'TGG', 'AGG', 'AGG', 'AGG', 'AGG', 'AGG', 'GGG', 'AGG', 'AGG', 'GGG', 'AGG', 'TGG', 'AGG', 'GGG', 'TGG', 'GGG', 'TGG', 'GGG', 'TGG', 'AGG', 'TGG', 'AGG', 'TGG', 'GGG', 'TGG', 'AGG', 'AGG', 'AGG', 'AGG', 'AGG', 'GGG', 'GGG', 'AGG', 'AGG', 'TGG', 'AGG', 'GGG', 'AGG', 'TGG', 'TGG', 'TGG', 'GGG', 'TGG', 'GGG', 'GGG', 'GGG', 'TGG', 'AGG', 'TGG', 'GGG', 'GGG', 'AGG', 'AGG', 'AGG', 'TGG', 'GGG', 'AGG', 'GGG', 'TGG', 'AGG', 'AGG', 'AGG', 'GGG', 'AGG', 'AGG', 'CGG', 'AGG', 'AGG', 'GGG', 'GGG', 'AGG', 'AGG', 'TGG', 'TGG', 'AGG', 'AGG', 'TGG', 'CGG', 'AGG', 'GGG', 'GGG', 'TGG', 'AGG', 'GGG', 'GGG', 'GGG', 'AGG', 'GGG', 'GGG', 'CGG', 'AGG', 'GGG', 'AGG', 'GGG', 'AGG', 'AGG', 'CGG', 'GGG', 'GGG', 'AGG', 'AGG', 'TGG', 'AGG', 'GGG', 'AGG', 'TGG', 'AGG', 'AGG', 'AGG', 'AGG', 'TGG', 'GGG', 'TGG', 'GGG', 'CGG', 'GGG', 'GGG', 'TGG', 'AGG', 'CGG', 'GGG', 'TGG', 'GGG', 'CGG', 'GGG', 'TGG', 'GGG', 'GGG', 'GGG', 'AGG', 'GGG', 'AGG', 'TGG', 'GGG', 'GGG', 'GGG', 'CGG', 'TGG', 'TGG', 'AGG', 'CGG', 'CGG', 'TGG', 'CGG', 'GGG', 'AGG', 'AGG', 'TGG', 'GGG', 'AGG', 'TGG', 'GGG', 'GGG', 'GGG', 'GGG', 'AGG', 'GGG', 'CGG', 'TGG', 'GGG', 'CGG', 'GGG', 'CGG', 'AGG', 'CGG', 'CGG', 'AGG', 'AGG', 'CGG', 'CGG', 'TGG', 'GGG', 'CGG', 'TGG', 'TGG', 'CGG', 'CGG', 'CGG', 'AGG', 'AGG', 'AGG', 'CGG', 'CGG', 'AGG', 'CGG', 'CGG', 'GGG', 'GGG', 'CGG', 'GGG', 'GGG', 'CGG', 'AGG', 'TGG', 'AGG', 'TGG', 'GGG', 'CGG', 'CGG', 'AGG', 'CGG', 'AGG', 'TGG', 'GGG', 'GGG', 'TGG', 'TGG', 'GGG', 'CGG', 'CGG', 'CGG', 'AGG', 'CGG', 'TGG', 'CGG', 'TGG', 'GGG', 'TGG', 'AGG', 'TGG', 'AGG', 'AGG', 'CGG', 'TGG', 'AGG', 'GGG', 'CGG', 'GGG', 'CGG', 'AGG', 'TGG', 'TGG', 'CGG', 'TGG', 'CGG', 'TGG', 'GGG', 'CGG', 'GGG', 'CGG', 'CGG', 'TGG', 'CGG', 'TGG', 'TGG', 'TGG', 'GGG', 'GGG', 'GGG', 'CGG', 'GGG', 'CGG', 'CGG', 'TGG', 'CGG', 'CGG', 'TGG', 'TGG', 'GGG', 'AGG', 'CGG', 'CGG', 'CGG', 'GGG', 'CGG']\n",
      "\n",
      "\n",
      "Constructing sencondary structure features.\n",
      "N-None,N2-441\n",
      "N-None,N2-441\n",
      "Constructing nucleotide features.\n",
      "N-None,N2-441\n",
      "N-None,N2-441\n",
      "After embedding\n",
      "X shape (441, 22)\n",
      "X  [[1 5 5 ... 5 4 4]\n",
      " [1 5 4 ... 4 4 5]\n",
      " [1 5 4 ... 4 4 2]\n",
      " ...\n",
      " [1 5 3 ... 5 5 4]\n",
      " [1 3 5 ... 5 4 5]\n",
      " [1 5 4 ... 5 5 4]]\n",
      "X_biofeat  [[  0.          -2.5        -36.8        ...  -3.12471508  26.30424722\n",
      "  -38.85892987]\n",
      " [  1.           0.         -37.6        ...   0.74561723  24.26227552\n",
      "  -31.22654346]\n",
      " [  0.          -0.1        -42.1        ...  -6.10138847  35.44618421\n",
      "  -44.28225742]\n",
      " ...\n",
      " [  0.          -7.6        -32.6        ...   2.06706272  28.07812522\n",
      "  -48.73877363]\n",
      " [  0.          -6.2        -33.2        ...   5.53841146  26.1361581\n",
      "  -53.61167482]\n",
      " [  0.          -5.6        -34.         ...   8.93631616  31.6914622\n",
      "  -44.28225742]]\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 441 entries, 247 to 57\n",
      "Data columns (total 6 columns):\n",
      "index         441 non-null int64\n",
      "Strand        441 non-null object\n",
      "Cut_Pos       441 non-null int64\n",
      "PAM           441 non-null object\n",
      "gRNA_Seq      441 non-null object\n",
      "Efficiency    441 non-null float32\n",
      "dtypes: float32(1), int64(2), object(3)\n",
      "memory usage: 22.4+ KB\n",
      "None\n",
      "         \n",
      "     index Strand  Cut_Pos  PAM              gRNA_Seq  Efficiency\n",
      "247    247      -      603  AGG  GGGGAAGAAGAGAGGCAGAG     0.73690\n",
      "171    171      -       40  TGG  AGAGGAAGATGCTACACTGG     0.73666\n",
      "242    242      -      575  AGG  GGAGGACCCGGAGAAAACGC     0.73292\n",
      "246    246      -      595  AGG  AGGACAAAGGGGAAGAAGAG     0.73208\n",
      "245    245      -      584  GGG  GGAGAAAACGCAGGACAAAG     0.73119\n",
      "421    421      -     2207  TGG  CAGTCTGGCTTTAACAACCC     0.72962\n",
      "221    221      -      393  GGG  GACAGAGACTGGGAGAATGG     0.72849\n",
      "292    292      -      856  GGG  TGGGATGCGTATGAACCGCG     0.72746\n",
      "311    311      -      950  GGG  CTCGAGGAGAGCGTTCCTGG     0.72719\n",
      "396    396      -     1956  AGG  GTCTGTAAGCAGGTTCGTGG     0.72406\n",
      "229    229      -      504  AGG  GGAGAAAGGCCCTGATGCCC     0.72004\n",
      "290    290      -      854  CGG  GATGGGATGCGTATGAACCG     0.71856\n",
      "77      77      +      805  AGG  CATGAACCTTCACAACAACG     0.71850\n",
      "423    423      -     2209  GGG  GTCTGGCTTTAACAACCCTG     0.71683\n",
      "187    187      -      166  TGG  AGGGAGAAAGGAGAGAAGAG     0.71665\n",
      "176    176      -       69  TGG  GGAGCCGCTAATAGCTACAG     0.71519\n",
      "349    349      -     1421  TGG  TGCATGAGCCGGACATCCCG     0.71417\n",
      "62      62      +      697  GGG  GGGCCCCGACTGGCACTGGG     0.70513\n",
      "304    304      -      923  GGG  GTGCTAGCGAGTCTGTTTGG     0.70462\n",
      "181    181      -      127  AGG  TGAGAAACTGAGGAGAGAAG     0.70456\n",
      "96      96      +     1030  CGG  GCGCCTGGAGCCGGAAGACC     0.70396\n",
      "103    103      +     1128  GGG  TGGGCACAGCAGGCACGGCA     0.70235\n",
      "294    294      -      870  AGG  ACCGCGGGGAGTGTGACTGG     0.70201\n",
      "205    205      -      319  AGG  GATGAGGAGGCAGGACAGGA     0.70197\n",
      "298    298      -      882  GGG  GTGACTGGAGGTACTCGGGT     0.70167\n",
      "60      60      +      695  GGG  GGGGGCCCCGACTGGCACTG     0.70084\n",
      "106    106      +     1184  CGG  GGCTGCGAGCTGCTCTGCTG     0.70065\n",
      "220    220      -      392  GGG  CGACAGAGACTGGGAGAATG     0.69997\n",
      "329    329      -     1226  GGG  CGAAGTAGACGAGGTCGTGG     0.69967\n",
      "182    182      -      128  GGG  GAGAAACTGAGGAGAGAAGA     0.69904\n",
      "..     ...    ...      ...  ...                   ...         ...\n",
      "164    164      +     2058  GGG  ATAAAACTATTTATTGTGCT     0.34544\n",
      "333    333      -     1234  CGG  ACGAGGTCGTGGGGGGAGGG     0.34137\n",
      "232    232      -      516  AGG  TGATGCCCAGGTGTGGGTTC     0.34124\n",
      "299    299      -      893  CGG  TACTCGGGTGGGCGAATAAC     0.32934\n",
      "321    321      -     1140  AGG  CGCGGGCGACGAGCTGTTAC     0.32577\n",
      "65      65      +      734  CGG  ATTGACTTCGGCCGCCTCTT     0.32387\n",
      "98      98      +     1108  TGG  CTGCACGTACAGCGGACGCC     0.32358\n",
      "144    144      +     1781  AGG  TGAACCCACACCTGGGCATC     0.31860\n",
      "389    389      -     1862  TGG  TGTGCAGGATCCCCGGATTT     0.31788\n",
      "428    428      -     2220  CGG  ACAACCCTGGGGGCGGGCGG     0.31752\n",
      "92      92      +      997  GGG  CGGCAGCAACCGCGCTTCGC     0.31402\n",
      "276    276      -      762  AGG  AGGTCCGGGGCAGGTCCATC     0.30919\n",
      "409    409      -     2128  TGG  TGCTGCAGTTGCGGCGACTT     0.30815\n",
      "163    163      +     2057  TGG  AATAAAACTATTTATTGTGC     0.29917\n",
      "167    167      +     2188  TGG  TCAAAGATGCGTTTGCCTCC     0.29710\n",
      "407    407      -     2091  TGG  CCAGAGCCCCATGGCCTGCC     0.29563\n",
      "20      20      +      271  TGG  GGCCGCTCTGCCCGCAGCCC     0.27989\n",
      "367    367      -     1616  CGG  GGCCCCCGGGGCCGCGCCGC     0.27971\n",
      "13      13      +      204  TGG  CCAGGCAGGCCATGGGGCTC     0.27514\n",
      "381    381      -     1759  TGG  TTGCCGAAGAGGTGGGGCCC     0.26823\n",
      "351    351      -     1446  CGG  CTTGCACTCCTGGCGCATCT     0.26586\n",
      "1        1      +       35  GGG  GCCGCCTCAGCCCACCAGCC     0.26303\n",
      "339    339      -     1262  AGG  GGGCCGGGTCTTCCGGCTCC     0.25284\n",
      "166    166      +     2143  TGG  TTTCTCCCTGCAGCCTTTTC     0.21866\n",
      "233    233      -      517  GGG  GATGCCCAGGTGTGGGTTCA     0.21207\n",
      "41      41      +      533  CGG  GCTCCAGGGCCCCACCTCTT     0.20931\n",
      "400    400      -     2006  AGG  GGCCACTGCTGTTGGCAGCC     0.13847\n",
      "165    165      +     2069  TGG  TATTGTGCTGGGTCCCAGCC     0.11031\n",
      "47      47      +      607  CGG  CTCCGCCGGGGTCACCCATT     0.07231\n",
      "57      57      +      687  TGG  GCGGCCCCGGGGGCCCCGAC     0.04662\n",
      "\n",
      "[441 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "result2 = effciency_predict(seq, \"wt_u6\")\n",
    "\n",
    "print(result2.info())\n",
    "\n",
    "print(\"         \")\n",
    "\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Prediction metrics demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.realpath( './' )\n",
    "esp_model_file_path = os.path.join( dir_path, 'models/esp_rnn_model.hd5' )\n",
    "hf_model_file_path = os.path.join( dir_path, 'models/hf_rnn_model.hd5' )\n",
    "model_esp = load_model( esp_model_file_path)\n",
    "model_hf = load_model( hf_model_file_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.007770613899385625', 'Spearman:0.8861134817457584')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## esp model prediction metrics\n",
    "get_metrics(model_esp,'esp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.008558173115465145', 'Spearman:0.8805147791848338')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hf model prediction metrics\n",
    "get_metrics(model_hf,'hf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Model training demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eSpCas9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13383222752668912755\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44841 samples, validate on 4983 samples\n",
      "Epoch 1/45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6a228b4bf201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         'optimizer':'6'}\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtrained_esp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\robin\\OneDrive\\Bureaublad\\DeepHF-master\\training_util.py\u001b[0m in \u001b[0;36mlstm_model\u001b[1;34m(model_type, batch_size, epochs, initializer, em_dim, em_drop, rnn_units, rnn_drop, rnn_rec_drop, fc_num_hidden_layers, fc_num_units, fc_drop, fc_activation, optimizer, learning_rate, validation_split, shuffle)\u001b[0m\n\u001b[0;32m    101\u001b[0m                  \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                  \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                  callbacks=[get_best_model, early_stopping])    \n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\robin\\anaconda3\\envs\\crispr\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param = {'model_type':'esp',\n",
    "        'em_drop':0.2,\n",
    "        'rnn_drop':0.5,\n",
    "        'rnn_rec_drop':0.4,\n",
    "        'fc_drop':0.4,\n",
    "        'batch_size':80,\n",
    "        'epochs':45,\n",
    "        'em_dim':44,\n",
    "        'rnn_units':80,\n",
    "        'fc_num_hidden_layers':3,\n",
    "        'fc_num_units':300,\n",
    "        'fc_activation':'3',\n",
    "        'optimizer':'6'}\n",
    "\n",
    "trained_esp_model = lstm_model(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.0074479781967959095', 'Spearman:0.8921754376074847')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(trained_esp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cas9-HF1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43518 samples, validate on 4836 samples\n",
      "Epoch 1/45\n",
      " - 24s - loss: 0.2527 - val_loss: 0.0410\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04102, storing weights.\n",
      "Epoch 2/45\n",
      " - 22s - loss: 0.0476 - val_loss: 0.0380\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04102 to 0.03800, storing weights.\n",
      "Epoch 3/45\n",
      " - 22s - loss: 0.0428 - val_loss: 0.0355\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03800 to 0.03550, storing weights.\n",
      "Epoch 4/45\n",
      " - 22s - loss: 0.0395 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03550 to 0.03306, storing weights.\n",
      "Epoch 5/45\n",
      " - 23s - loss: 0.0355 - val_loss: 0.0293\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03306 to 0.02933, storing weights.\n",
      "Epoch 6/45\n",
      " - 22s - loss: 0.0318 - val_loss: 0.0268\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02933 to 0.02677, storing weights.\n",
      "Epoch 7/45\n",
      " - 1413s - loss: 0.0294 - val_loss: 0.0246\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02677 to 0.02462, storing weights.\n",
      "Epoch 8/45\n",
      " - 1637s - loss: 0.0267 - val_loss: 0.0220\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02462 to 0.02202, storing weights.\n",
      "Epoch 9/45\n",
      " - 88s - loss: 0.0246 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02202 to 0.02023, storing weights.\n",
      "Epoch 10/45\n",
      " - 88s - loss: 0.0230 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02023 to 0.01890, storing weights.\n",
      "Epoch 11/45\n",
      " - 87s - loss: 0.0212 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01890 to 0.01733, storing weights.\n",
      "Epoch 12/45\n",
      " - 89s - loss: 0.0199 - val_loss: 0.0162\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01733 to 0.01617, storing weights.\n",
      "Epoch 13/45\n",
      " - 87s - loss: 0.0186 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01617 to 0.01465, storing weights.\n",
      "Epoch 14/45\n",
      " - 88s - loss: 0.0178 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01465 to 0.01435, storing weights.\n",
      "Epoch 15/45\n",
      " - 88s - loss: 0.0171 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01435 to 0.01391, storing weights.\n",
      "Epoch 16/45\n",
      " - 87s - loss: 0.0165 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01391 to 0.01367, storing weights.\n",
      "Epoch 17/45\n",
      " - 87s - loss: 0.0160 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01367 to 0.01305, storing weights.\n",
      "Epoch 18/45\n",
      " - 88s - loss: 0.0154 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01305 to 0.01261, storing weights.\n",
      "Epoch 19/45\n",
      " - 88s - loss: 0.0150 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01261 to 0.01244, storing weights.\n",
      "Epoch 20/45\n",
      " - 87s - loss: 0.0148 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01244 to 0.01208, storing weights.\n",
      "Epoch 21/45\n",
      " - 87s - loss: 0.0145 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01208 to 0.01200, storing weights.\n",
      "Epoch 22/45\n",
      " - 89s - loss: 0.0140 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01200 to 0.01197, storing weights.\n",
      "Epoch 23/45\n",
      " - 87s - loss: 0.0138 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01197 to 0.01158, storing weights.\n",
      "Epoch 24/45\n",
      " - 87s - loss: 0.0135 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01158 to 0.01145, storing weights.\n",
      "Epoch 25/45\n",
      " - 87s - loss: 0.0132 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01145 to 0.01126, storing weights.\n",
      "Epoch 26/45\n",
      " - 1070s - loss: 0.0129 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01126 to 0.01113, storing weights.\n",
      "Epoch 27/45\n",
      " - 706s - loss: 0.0128 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01113 to 0.01108, storing weights.\n",
      "Epoch 28/45\n",
      " - 23s - loss: 0.0125 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00028: val_loss did not improve.\n",
      "Epoch 29/45\n",
      " - 23s - loss: 0.0124 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01108 to 0.01092, storing weights.\n",
      "Epoch 30/45\n",
      " - 24s - loss: 0.0122 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01092 to 0.01082, storing weights.\n",
      "Epoch 31/45\n",
      " - 26s - loss: 0.0120 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01082 to 0.01073, storing weights.\n",
      "Epoch 32/45\n",
      " - 23s - loss: 0.0119 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00032: val_loss did not improve.\n",
      "Epoch 33/45\n",
      " - 23s - loss: 0.0117 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01073 to 0.01065, storing weights.\n",
      "Epoch 34/45\n",
      " - 26s - loss: 0.0115 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01065 to 0.01052, storing weights.\n",
      "Epoch 35/45\n",
      " - 25s - loss: 0.0114 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00035: val_loss did not improve.\n",
      "Epoch 36/45\n",
      " - 23s - loss: 0.0113 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01052 to 0.01046, storing weights.\n",
      "Epoch 37/45\n",
      " - 24s - loss: 0.0111 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01046 to 0.01040, storing weights.\n",
      "Epoch 38/45\n",
      " - 25s - loss: 0.0110 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01040 to 0.01037, storing weights.\n",
      "Epoch 39/45\n",
      " - 26s - loss: 0.0109 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01037 to 0.01027, storing weights.\n",
      "Epoch 40/45\n",
      " - 28s - loss: 0.0108 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00040: val_loss did not improve.\n",
      "Epoch 41/45\n",
      " - 25s - loss: 0.0107 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01027 to 0.01023, storing weights.\n",
      "Epoch 42/45\n",
      " - 24s - loss: 0.0105 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00042: val_loss did not improve.\n",
      "Epoch 43/45\n",
      " - 23s - loss: 0.0104 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01023 to 0.01011, storing weights.\n",
      "Epoch 44/45\n",
      " - 23s - loss: 0.0103 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00044: val_loss did not improve.\n",
      "Epoch 45/45\n",
      " - 25s - loss: 0.0103 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00045: val_loss did not improve.\n",
      "Using epoch 00043 with val_loss: 0.01011.\n"
     ]
    }
   ],
   "source": [
    "param = {'model_type':'hf',\n",
    "    'em_drop': 0.2, \n",
    "     'rnn_drop': 0.5, \n",
    "     'rnn_rec_drop': 0.4, \n",
    "     'fc_drop': 0.5, \n",
    "     'batch_size': 80, \n",
    "     'epochs': 45, \n",
    "     'em_dim': 48, \n",
    "     'rnn_units': 80, \n",
    "     'fc_num_hidden_layers': 2, \n",
    "     'fc_num_units': 300, \n",
    "     'fc_activation': 3, \n",
    "     'optimizer': 6}\n",
    "\n",
    "trained_hf_model = lstm_model(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MES:0.008565540312178864', 'Spearman:0.8803655561707214')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(trained_hf_model,'hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crispr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
